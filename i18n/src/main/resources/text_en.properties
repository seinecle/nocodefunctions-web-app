#Tue Feb 14 10:06:33 CET 2023
=
acknowledgements.argument1.title=Thanks to the dev community for providing tools and support and for sharing their knowledge. This app leverages these projects\:
acknowledgements.argument2.title=Thanks to Gilles Maltais for his contribution to the Quebec vocabulary.
acknowledgements.argument3.title=Thanks to  Ver\u00f3nica Espinoza for her feedbacks on nocodefunctions.com and on the Umigon function in particular.
acknowledgements.argument4.title=Thanks to Martin Zacarias for his feedback on the pdf matcher function.
acknowledgements.argument5.title=Thanks to all the anonymous users for their feedbacks on Umigon through the feedback form.
acknowledgements.argument6.title=Thanks to DMDS students Anna Abreu, Hiya Barnejee, L\u00e9o Couder, Terje Espedal and Aparna Ramakrishnan for their contribution to the early steps of the project on emotion detection
acknowledgements.argument7.title=Thanks to Jos\u00e9 Manuel Le\u00f3n Ranero for helping debugging the Excel import
acknowledgements.description=Thanking individuals and organizations for the tools they build and that support Nocode functions
acknowledgements.tagline=Thank you\!
acknowledgements.title=Acknowledgements - thanks to those making Nocode functions possible
back.categorizationbean.categories_are_saved=categories are saved
back.import.error_fetching_tweets=\ud83d\ude1e Error\: impossible to fetch tweets
back.import.file_extension_not_recognized=the file extension was not recognized. Please rename your file with a more common, simple extension
back.import.file_successful_upload.closing=" successfully uploaded
back.import.file_successful_upload.opening=\u2b50 file "
back.import.files_uploaded=files uploaded
back.import.json_key_missing=you must write the name of the json key pointing to the textual value to be analyzed
back.import.select_for_one_json_per_line=select this checkbox if your file is made of separate json objects or json arrays per line.
back.import.finished_searching_tweets=\u2b50 finished searching, 
back.import.number_tweets_found=\ tweets found
back.import.one_file_uploaded=one file uploaded
back.import.reading_sheet=\ud83d\udcc3 reading spreadsheet
back.import.searching_tweets=\ud83d\udd26 searching for tweets
back.import.select_one_column_per_type=\ud83d\ude15 select exactly one column per type
back.import.term_text_different_columns=\ud83d\ude15 terms and texts should be in different columns
back.import.twitter.too_many_requests=\u231b Too many requests to the Twitter API. You must wait and try again.
back.import.twitter_credentials_not\ found=\ud83e\udd9f credentials for Twitter were not found
back.import.two_columns_needed=\ud83d\ude15 two different columns must be selected\: one for the terms, the other for the texts
back.topics.detecting_communities=\ud83c\udfc1\ufe0f last steps\: finding topics / communities
cowo.cowo.max_size_for_ngrams=Choose the maximum length for ngrams. The default length is\:
cowo.cowo.remove_academic_stopwords=Remove 'academic' stopwords\: words which are typical of the academic discourse (on texts in English and French only)\n
cowo.cowo.remove_smaller_words=Remove small words. Default minimum characters for a word is
cowo.cowo.remove_infrequent_words=Exclude words that have fewer than this number of occurrences: 
cowo.cowo.tagline=\ud83d\udd78\ufe0f turn your texts into networks - parameters
cowo.cowo.title=Cowo\: a free online tool to create semantic networks from text
cowo.results.long_explanation=<h3>The function has created a network where\:</h3>\n<ul>\n<li>only the most frequent expressions appear</li>\n<li>if 2 expressions appear often together in the text, they are connected in the network</li>\n</ul>\n<p>The graph visualized above shows the 20 most frequent expressions in the text.</p>\n\n<h3>Visualize the graph with Gephi, VOSviewer or Gephisto</h3>\n<p>You can download the full network (not just the sample shown here) as a <strong>gexf file</strong> with all the information about the network. <strong>Gexf files</strong> can be opened and explored with <a href\="https\://gephi.org" target\="_blank">Gephi</a>, the leading free desktop software for network visualizations.</p>\n<br/>\n<p>You can also directly visualize the network with <a href\="https\://www.vosviewer.com/" target\="_blank">VOSviewer</a> online, the software developed by Nees Jan van Eck and Ludo Waltman at the Centre for Science and Technology Studies (CWTS) at Leiden University.</p>\n<br/>\n<p>Last, <a href\="https\://jacomyma.github.io/gephisto/" target\="_blank">Gephisto</a> is a web application that creates a viz in one click, that you can download as a PNG file.</p>
cowo.results.tagline=\ud83d\udd78\ufe0f turn your texts into networks - results
cowo.results.title=Cowo\: turn your texts into networks -results.
cowo.tool.argument1.details=If you use this function, please cite:
cowo.tool.argument1.title=Semantic networks - turn your texts into graphs
cowo.tool.argument2.details=The function takes one parameter (what is the language of the text?) and runs with one click\:\n
cowo.tool.argument3.details=<p>\n<strong>Structure and format of the text</strong>\: the network is created by detecting pairs of terms which appear on the same line of text. So you should be careful about how your text is split. Ideally, it should be made of relatively short paragraphs, each on one line. If you are using an Excel file, each paragraph or significant block of text should appear on a different row.\n<br/>\n<br/>\n<strong>Pre-processing of the text</strong>\: there is no need to pre-process or clean your text before using this function.\n<br/>\n<br/>\n<strong>Exploring the graph</strong>\: we recommend two free professional grade software for the exploration of the semantic network produced by the function. <a href\="https\://gephi.org" target\="_blank">Gephi</a> provides the best features to filter, colorize, resize and run descriptive graph statistics on your network (such as <a href\="https\://en.wikipedia.org/wiki/Betweenness_centrality" target\="_blank">betweenness centrality</a>). <a href\="https\://www.vosviewer.com/" target\="_blank">VOSviewer</a> provides the visualizations which are the cleanest and easiest to interpret for semantic networks. VOSviewer is developed with scientometrics as first use case but it is useful for any kind of semantic network.\n</p>\n
cowo.tool.argument3.title=Tips and tricks to get insights from a semantic network
cowo.tool.argument4.details=If your text is a list of co-occurrences or a list of items, you might want to use Gaze, a function dedicated to <a href\="../gaze/network_builder_tool.html">building networks from co-occurrences and similarities</a>.\n
cowo.tool.argument4.title=When your text is structured, with lists of items
cowo.tool.description=100% free online tool to create semantic networks. No registration required. Import your text in csv, Excel or plain text. Run the analysis in one click. Download your results in Excel or as a graph.
cowo.tool.model_long_details=<p>\nThe principles followed by the tool are described in this academic publication studying <a href\="https\://management-aims.com/index.php/mgmt/article/view/4245" target\="_blank">how to find communities and topics on Twitter</a>. The technology follows these steps\:\n</p>\n<ol>\n<li>cleaning of the text\: flatten to ASCII, removal of urls, removal of punctuation signs.</li>\n<li>lemmatization.</li>\n<li>decomposition of the text in <a href\="https\://en.wikipedia.org/wiki/N-gram" target\="_blank">n-grams</a> up to four-grams, removal of less relevant n-grams. This step is identical to the one followed by the <a href\="../umigon/sentiment_analysis_tool.html">function for sentiment analysis</a></li>\n<li>count of <a href\="https\://en.wikipedia.org/wiki/Co-occurrence" target\="_blank">co-occurrences</a>\: which pairs of n-grams tend to appear frequently in the same lines of the text?</li>\n<li>the list of cooccurring n-grams is used to create a network\: it is made of the most frequent n-grams. Two n-grams are connected if they are frequently cooccurring.</li>\n<li>the strength of the connections in the network is corrected using a procedure called <a href\="https\://nocodefunctions.com/blog/pmi-tf-idf/" target\="_blank">Pointwise Mutual Information (PMI)</a>.</li>\n</ol>
cowo.tool.model_short_details=The function identifies pairs of terms in each line of the text. These pairs are called co-occurrences. Aggregating all pairs of terms and selecting the most frequent ones, a network of terms is constructed where any two terms are connected if they often appear together in the text.
cowo.tool.tagline=\ud83d\udd78\ufe0f Free tool to turn your texts into semantic graphs
cowo.tool.title=Tool to generate semantic networks, free and online. Turn texts into graphs.
delight.results.tagline=Detection of 'delight' in English social media texts - results
delight.tool.description=Free tool to identify 'delight' as an emotion in texts from English social media.
delight.tool.tagline=\ud83d\ude0a \ud83d\ude02 \ud83d\udc4d Free tool to identify delight in texts, for social media in English
delight.tool.title=Identify the emotion 'delight' in texts, free and online. Opinion mining for non coders.
gaze.network_builder.apply_pmi_correction=Apply a <a href\="https\://en.wikipedia.org/wiki/Pointwise_mutual_information" target\="_blank">Pointwise Mutual Correction (PMI) correction</a> to the connections of the network.\n
gaze.network_builder.connections_should_have_min_targets_in_common=You can decide that to create a connection, 2 sources should have a least a number of targets in common. The default minimum value is one.
gaze.network_builder.description=100% free online tool to create networks from lists
gaze.network_builder.go_with_option=Choose option
gaze.network_builder.if_you_need_more_parameters=if you need more parameters \ud83e\udd13
gaze.network_builder.option_1=Option 1\: cooccurences to network
gaze.network_builder.option_2=Option 2\: sources and targets to network
gaze.network_builder.or_read_below=... or read below about these two options, and how they work\:
gaze.network_builder.tagline=\ud83d\udd27\ufe0f\ufe0f Free tool to create networks from co-occurrences or lists
gaze.network_builder.tips_and_tricks.details=<strong>Exploring the graph</strong>\n<br/>We recommend two free software for the exploration of the semantic network produced by the function\:\n<ul>\n<li><a href\="https\://gephi.org" target\="_blank">Gephi</a> provides the best features to filter, colorize, resize and run descriptive graph statistics on your network (such as betweenness centrality).\n</li>\n<li> <a href\="https\://www.vosviewer.com/" target\="_blank">VOSviewer</a> provides the visualizations which are the cleanest and easiest to interpret for semantic networks. VOSviewer is developed with scientometrics as first use case but it is useful for any kind of semantic network.\n</li>\n</ul>
gaze.network_builder.tips_and_tricks.title=Tips and tricks to get insights from the network
gaze.network_builder.title=Tool to generate networks, free and online. Turn csv and co-occurrences into graphs.
gaze.network_builder.two_options=Two options\: co-occurrences or similarities in lists
gaze.network_builder.use_it_directly=Use it directly by choosing an option\:
gaze.results.long_explanation=<h3>The function has created a network where\:</h3>\n<ul>\n<li>\n<strong>If you chose Option 1 (co-occurrences)</strong>\: when 2 expressions co-occur on one or many lines, they are connected in the network\n</li>\n<li>\n<strong>If you chose Option 2 (sources and targets)</strong>\: when 2 sources have at least one target in common, they are connected in the network.\n</li>\n</ul>\n\n<h3>Visualize the graph with Gephi, VOSviewer or Gephisto</h3>\n<p>You can download the full network (with many more expressions) as a <strong>gexf file</strong> with all the information about the network. \n<strong>Gexf files</strong> can be opened and explored with <a href\="https\://gephi.org" target\="_blank">Gephi</a>, the leading free desktop software for network visualizations.\n</p>\n<br/>\n<p>\nYou can also directly visualize the network with <a href\="https\://www.vosviewer.com/" target\="_blank">VOSviewer</a> online, the software developed by Nees Jan van Eck and Ludo Waltman at the Centre for Science and Technology Studies (CWTS) at Leiden University.\n</p>\n<br/>\n\n<p>\nLast, <a href\="https\://jacomyma.github.io/gephisto/" target\="_blank">Gephisto</a> is a web application that creates a viz in one click, that you can download as a PNG file.\n</p>\n<br/> 
gaze.results.tagline=\ud83d\udd27\ufe0f\ufe0f\ufe0f Gaze\: build a network from cooccurrences or similarities - results
gaze.results.title=Results - Create networks from cooccurrences or lists of entities
general.languages.arabic=Arabic
general.languages.bulgarian=Bulgarian
general.languages.catalan=Catalan
general.languages.danish=Danish
general.languages.dutch=Dutch
general.languages.english=English
general.languages.french=French
general.languages.german=German
general.languages.greek=Greek
general.languages.italian=Italian
general.languages.japanese=Japanese
general.languages.norwegian=Norwegian
general.languages.polish=Polish
general.languages.portuguese=Portuguese
general.languages.romanian=Romanian
general.languages.russian=Russian
general.languages.spanish=Spanish
general.languages.turkish=Turkish
general.message.almost_done=\u23f3 almost done
general.message.analysis_complete=\u2728 analysis is complete
general.message.are_not_connected=are not connected
general.message.at_least=At least\:
general.message.back_to_menu=back to menu
general.message.back_to_the_menu=Back to the menu
general.message.captcha_paris=Please fill in this captcha\: what is the capital of France?
general.message.check_spam=please check the spam folder
general.message.choose_gexf_file=Choose a gexf file (Gephi)
general.message.json=Import a .json file (and specify which key holds the textual data)
general.message.choose_vosviewer_file=Choose a json file (VOSviewer)
general.message.cleaning_key_terms=\ud83d\udec1 cleaning key terms and expressions... 
general.message.confirm_and_back_to_menu=Confirm your parameters and get back to the main panel
general.message.data_not_found=\ud83e\udd14 data not found
general.message.dataset_is_made_of=The dataset you uploaded is made of
general.message.describe_items_short=Describe these items in a short line\:
general.message.download_gexf=download gexf file
general.message.analyze_url=Analyze the text contained in a web page
general.message.paste_url=Paste the url (link) of the web page you want to analyze
general.message.example_url=https://en.wikipedia.org/wiki/Natural_language_processing
general.message.email_sent=\ud83d\udce7 email sent
general.message.email_sent_to=\ud83d\udce7 email sent to\:
general.message.empty_line=empty line
general.message.error_function_not_set=No function was selected, the files cannot be uploaded.
general.message.error_url_timed_out=url cannot be reached because the connection timed out.
general.message.error_no_connection=url cannot be reached because it is broken or the connection is bad
general.message.case_sensitive=case sensitive
general.message.fetch_content_url=Fetch the text of this page
general.message.feedback_sent=your feedback has been sent
general.message.content_successful_read=content was read successfully
general.message.file_loaded=\ud83d\ude9a file loaded\!
general.message.finding_key_terms=\ud83c\udfaf finding key terms and expressions... 
general.message.finished_reading_data=\u2b50 finished reading the data
general.message.gephi.description=<p>\n<a href\="https\://gephi.org/" target\="_blank">Gephi</a> is a free desktop software to create, visualize and explore small and large networks.\nThe user can import, layout, filter, colorize, resize, and compute key metrics on the network.\n</p>\n<p>                            \nThis makes it an effective tool for the visual exploration of network data and for the visual communication of such data.                            \n</p>\n<p>\nUseful links\: <a href\="https\://seinecle.github.io/gephi-tutorials/" target\="_blank">Tutorials for Gephi</a> and the very active <a href\="https\://www.facebook.com/groups/gephi" target\="_blank">Facebook group of Gephi users</a>.\n</p>
general.message.gephi.long_title=Gephi - a generalist free software for network visualization
general.message.get_in_touch_if_need_support_new_language=(get in touch if you would need a new language to be supported)
general.message.go_back_do_search_twitter=go back and do another search on Twitter \ud83d\udd0e
general.message.heavy_duty_lemmatization=\ud83c\udfcb heavy duty lemmatization.
general.message.i_new_user=I am a new user
general.message.import_your_data_get_results_example=Import your data, get the results\: an example
general.message.import_text_from_web_page=Analyze the text from a web page
import_data.general.choose_web_page=Get the text from a web page to analyze it
general.message.internal_server_error=Internal server error. Please send a report to analysis@exploreyourdata.com
general.message.keep_it_short_exclamation=keep it short and clear\!
general.message.language_of_text_to_analyze=Select which is the language of the text\:
general.message.last_ops_creating_network=\ud83c\udfc1\ufe0f last operations\: creating the network
general.message.make_viz_public_details=<p>When you make the visualization public, a permanent link is generated. You can bookmark it and share the visualization.</p>\n<br/>\n<p>Otherwise, the file is deleted after one hour.</p>
general.message.make_viz_public_question=Make the visualization public?
general.message.max_file_size=\ud83d\udcda Maximum file size
general.message.max_items_capacity_to_analyze=Maximum number of items that will be analyzed\:
general.message.max_ngram=Length of ngrams
general.message.min_word_length=minimum word length
general.message.min_word_freq=minimum frequency for words
general.message.name_of_dataset=name of the dataset
general.message.new_api_available=New\: API access now available
general.message.no_file_upload_again=\ud83d\ude15 no file to read. Upload a file then try again.
general.message.ok_sharing_stopwords=click here if you agree these stopwords can be shared and re-used to improve the app for everyone \ud83d\ude4f
general.message.open_the_chart=Open the chart
general.message.opening_academic_stopwords=\ud83d\udebf\ufe0f opening stopwords from the academic discourse and using them
general.message.opening_user_supplied_stopwords=\ud83e\udd38 opening user supplied list of stopwords
general.message.or_read_explanations_below=... or read below about what it does, and how it works\:
general.message.password_will_be_sent_to_email=This password will be sent to your email address. Check your spam folder\!
general.message.please_use_api_for_bigger_capacity=Please use the API if you need a larger capacity
general.message.please_wait_seconds=please wait a few seconds.
general.message.providing_own_stopwords.details1=Upload a list of stopwords. It must be a .txt file with one word per line.
general.message.providing_own_stopwords.details2=Select this box if this list should replace (rather than add up to) the default stopword list.
general.message.providing_own_stopwords.details3=Select this box if you agree these stopwords can be shared and re-used to improve the app for everyone \ud83d\ude4f.
general.message.providing_own_stopwords.title=providing your own stopwords
general.message.reading_csv_file=\ud83d\udc53 Reading the csv file
general.message.import_text_from_web_site=Analyze the text of all the pages of a website
general.message.reading_excel_file=\ud83d\udc53 Reading the Excel spreadsheet
general.message.reading_file=Reading the file 
general.message.reading_google_spreadsheet=\ud83d\udc53 Reading the Google spreadsheet
general.message.reading_pdf_file=\ud83d\udc53 Reading the pdf file
general.message.reading_text_file=\ud83d\udc53 Reading the text file
general.message.remove_academic_stopwords=remove academic stopwords
general.message.remove_science_stopwords=Remove 'science' stopwords
general.message.remove_stopwords_small_words=\ud83d\udebf\ufe0f removing stopwords and very small words
general.message.removing_punctuation_and_cleaning=\ud83d\udec1 removing punctuations and other cleaning ops
general.message.reportsent=report is sent
general.message.scores_by_annotators=scores by annotators
general.message.see_more_details=more details\:
general.message.sending_user_stopwords_to_dev=\u2709 \ufe0fsending the list of stopwords to the developer - will be integrated soon, thank you\! \ud83d\ude4f
general.message.several_files_possible=You can analyze *several* files at once. To analyze all the files in a folder, open the folder and use 'Ctrl', 'shift' or 'Cmd' keys to select all the files you want to include in the analysis.\n
general.message.should_be=should be
general.message.starting_analysis=\ud83c\udfc3 starting the analysis
general.message.switch_to_desktop=Please switch to a browser on a desktop computer.
general.message.text_in_bulk_one_item_per_line=Items in a plain .txt file - one item per line \ud83d\udcc4
general.message.text_in_bulk_pdf_only=Select pdf files
general.message.text_in_tables_one_item_per_line=Items which are in a specific column of a file (csv or Excel file) \ud83d\udcca
general.message.text_provided_as_input=text provided as input
general.message.text_structured=Structured text in columns or tables (csv or Excel files)
general.message.the_product_of=The product of
general.message.try_it_just_click_on_link=Try it, just click on the link\:
general.message.type_your_query=Type your query
general.message.upload_your_data=Upload your data
general.message.use_it_directly_by_selecting_a_data_source=Use it directly by selecting the data to be analyzed\:
general.message.use_own_stopwords=use your own stopwords
general.message.use_own_stopwords.instructions=Upload a list of stopwords. It must be a .txt file with one word or n-gram per line.\n
general.message.use_pmi=use PMI
general.message.user_exists=\ud83d\udea8 User already exists
general.message.file_extension_not_recognized=\ud83d\udea8 File extension not recognized.
general.message.encoding_error=\ud83d\udea8 Possible error with the encoding of your file. The text should be encoded in UTF-8.
general.message.user_exists.instructions=Please unselect 'new user' and login with 
general.message.visualize_with_gephisto=visualize with Gephisto
general.message.visualize_with_vosviewer=visualize with VOSviewer
general.message.vosviewer.description=<p>\n<a href\="https\://www.vosviewer.com/" target\="_blank">VOSviewer</a> is a free desktop software to create and visualize networks, with advanced capabilities in the domain of <a href\="https\://en.wikipedia.org/wiki/Scientometrics" target\="_blank">scientometrics</a> (which, briefly said, consists in the measurement and assessment of the scientific activity).\n</p>\n<p>\nIn Summer 2021, the developers of VOSviewer have launched <a href\="https\://github.com/neesjanvaneck/VOSviewer-Online/" target\="_blank">an online version</a>, which makes it very practical to share the visualizations created on it.\n</p>\n<p>\nUseful links\: <a href\="https\://www.vosviewer.com/getting-started" target\="_blank">Getting started with VOSviewer</a> which offers a collection of resources.\n</p>
general.message.vosviewer.long_title=VOSviewer - from scientometrics to generalist app to visualize semantic networks
general.message.wait_and_authorize_popup=Wait... and authorize pop up windows
general.message.wait_long_operation=\u23f3 This operation may take some time. Please wait.
general.message.write_here=write here
general.message.wrong_password=wrong password
general.message.wrong_password_or_email=wrong email or password
general.message.you_annotated=you annotated
general.message.you_are_logged_in=you are logged in
general.message.you_are_not_logged_in=you are not logged in
general.message.your_description_here=your description here
general.message.your_email=your email
general.message.your_password=your password
general.message.your_stopwords_replace=click here if your list of stopwords should *replace* the default list of stopwords
general.message.write_json_key_holding_data=write here the name of they key pointing to the textual data to analyze. Do not surround the name of the key with double quotes.
general.nouns.academic_stopwords=stopwords from the academic discourse
general.nouns.additional_parameters=additional parameters
general.nouns.annotator=Annotator
general.nouns.categories=categories
general.nouns.connections=connections
general.nouns.context=context
general.nouns.delight=delight
general.nouns.error=error
general.nouns.explanations=explanations
general.nouns.feedback=feedback
general.nouns.file=file
general.nouns.files=files
general.nouns.item=item
general.nouns.items=items
general.nouns.key_terms=key terms
general.nouns.label=label
general.nouns.line_number=line number
general.nouns.link=link (edge)
general.nouns.link_strength=strength ('weight') of the link
general.nouns.min_targets=Minimum of shared targets to create a connection
general.nouns.no_delight=no delight
general.nouns.node_source=node (source)
general.nouns.node_target=node (target)
general.nouns.occurrences=occurrences
general.nouns.page=page
general.nouns.parameters=parameters
general.nouns.pmi=Pointwise Mutual Information (PMI)
general.nouns.scores=scores
general.nouns.sentiment=sentiment
general.nouns.sentiment_negative=negative sentiment
general.nouns.sentiment_neutral=neutral sentiment
general.nouns.sentiment_positive=positive sentiment
general.nouns.status=status
general.nouns.success=success
general.nouns.term=term
general.nouns.text=text
general.nouns.topic=topic
general.nouns.topics=topics
general.small_words.all=all
general.small_words.and=and
general.small_words.and_then_capitalized=AND THEN
general.small_words.has=has
general.small_words.is=is
general.small_words.no=no
general.small_words.or=or
general.small_words.out_of=out of
general.small_words.there_are_still=There are still
general.small_words.why=why?
general.small_words.yes=yes
general.title.if_you_need_more_parameters=If you need more parameters \ud83e\udd13
general.title.model_long_description.title=The model - long description
general.title.model_short_description.title=The model - short description
general.verb.is_uploaded=is uploaded
general.verbs.compute=compute
general.verbs.confirm=confirm
general.verbs.confirm_options=confirm your options
general.verbs.delete=delete
general.verbs.download_results=download the results
general.verbs.hide=hide
general.verbs.logoff=log off
general.verbs.open_report=open the report
general.verbs.remove=remove
general.verbs.save=save
general.verbs.select_one=select one
general.verbs.send=send
general.verbs.signal_error=signal an error
general.verbs.wait_exclamation=wait\!
general_message.counting_pairs_terms=\ud83d\udcbb counting pairs of terms - this is computationally intensive and can take a dozen seconds. Please be patient.
general_message.empty_network_no_connection=\ud83d\ude14 the network has no connection
general_message.finished_pairs_removing_less_frequent=\ud83d\udebf\ufe0f finished computing pairs. Removing less frequent ones
general_message.retaining_freq_terms=\u2697\ufe0f retaining only the most frequent terms
header.menu.acknowledgements=Acknowledgements
header.menu.blog=Blog
header.menu.discuss=Discussion
header.menu.getsupport=Get support
header.menu.home=Home
header.menu.isitpopular=Counter of visits
header.menu.pricing=Pricing
header.menu.whodevelopsit=Who develops it?
header.menu.why=Why?
highlighter.results.download=Get the file with results
highlighter.results.tagline=\ud83c\udfa8\ufe0f\ufe0f Free tool to highlight a word in a text - download the results
highlighter.results.title=Free tool to highlight a word in a text with CSS - download the results
highlighter.tool.description=100% free online tool to to highlight a term in a text with css styling. No registration required. Import your text in csv or Excel.
highlighter.tool.explanation1=<p>The color effects are the result of adding an html tag\: &lt;span&gt; and css styling within it.</p>\n<br/>\n<br/>\n<p>The colors used to highlight can be customized\: color of the text and background color (see below).</p> 
highlighter.tool.input=<p>\n<strong>INPUT</strong>\: This function takes a list of words, plus a list of sentences ("context") where these words appear.\n</p> 
highlighter.tool.input1=I have moved to <span style\="background-color\: black;color\:whitesmoke;">Paris</span>
highlighter.tool.input2=The <span style\="background-color\: black;color\:whitesmoke;">Liverpool FC</span> is a professional football club
highlighter.tool.input3=The Vice President of <span style\="background-color\: black;color\:whitesmoke;">Barack Obama</span> was Joe Biden
highlighter.tool.output=<p><strong>OUTPUT</strong>\: A two-column Excel file ressembling the input, except that the terms are now highlighted in context\:</p>\n
highlighter.tool.tagline=\ud83c\udfa8\ufe0f\ufe0f Free tool to highlight a word in a text with CSS
highlighter.tool.title=Tool to highlight a term in a text with css styling
highlighter.tool.what_it_does_question=What is the goal of this function?
highlighter.tool.which_color_background=Which background color for the word to highlight?
highlighter.tool.which_color_word=Which color for the word to highlight?
import_data.bulk.title=Import your data as plain text
import_data.bulk.description=Upload unstructured data contained in text files or pdf files.
import_data.general.choose_csv_or_excel=Choose a csv or Excel file
import_data.general.choose_pdf=Choose pdf files
import_data.general.choose_json=Choose a .json file
import_data.general.choose_txt_or_pdf=Choose .txt or pdf files
import_data.general.click_below_to_read_it=Now, click the link below to read it.
import_data.general.my_data_has_headers=My data has headers
import_data.general.open_a_file=Open a file
import_data.general.preview_your_data=Preview of the data in the file you uploaded
import_data.general.preview_your_tweets=Preview of the results of the search on Twitter
import_data.general.read_data=Read the data in the file(s)
import_data.general.select_two_columns_below=Select two columns (below)
import_data.general.upload_a_dataset=Upload a dataset
import_data.option1.description=Some functions need to get for input files where each line will be examined, and within each line there is a list of items. This import page reads such files
import_data.option1.for_Excel_files=for Excel files, each item should be in a column\:
import_data.option1.for_csv_files=for plain text files and csv files, the items should be comma separated or any other separator will do as long as it is consistent across the file (space, semi-colon, tabs...)
import_data.option1.title=A page to import a dataset where co-occurrences will be detected line by line
import_data.option2.click_to_select_source=Click here to select this column as the source
import_data.option2.confirm_this_column_is_source=this column is the source, and the column(s) on the right are the target(s). Click on 'yes' to launch the analysis.
import_data.option2.description=Some functions reason on an input dataset which comprises 'source' entities and 'target' entities. This page allows for this import
import_data.option2.file_must_have_columns=Your file must include at least 2 columns\: the first one is the source. The column(s) on the right are the targets.
import_data.option2.title=A page to import a dataset with sources and targets
import_data.structured_data.click_for_this_column=Click here to analyze data in this column
import_data.structured_data.confirm_analysis_on_this_column=the analysis will be performed on this column if you click on 'yes'
import_data.structured_data.description=This page is for you to import a structured dataset to be analyzed by the function you selected
import_data.structured_data.title=Import a structured dataset - in csv or table format
import_data.twitter.connect=\ud83d\udcde Connect to Twitter
import_data.twitter.launch_the_search=launch the search
import_data.exclude_terms=Optional: a list of terms to be excluded
import_data.website.exclude_terms_instructions=Write any term which, if included in the url, will exclude this url. If you write several terms, separate them with a comma.
import_data.twitter.title=Search and import tweets
import_data.web_link_user_provided=web link provided by user
import_data.include_depth_1_links=Go to depth of +1: include the text of the web pages that the original page is linking to
import_data.two_columns.description=This page allows you to select a file, upload it and then select the two columns where the data of interest is located
import_data.two_columns.title=Import structured data with 2 columns
import_data.include_depth_1_links_question=include the text of web pages at depth + 1?
import_data.include_this_link_question=include the text on this web page?
import_data.you_need_to_do_step_one_first=To see the web page links to include (or not), you must have clicked on the button at step 1, above.
import_data.website.max_links_defaut_value=Default value is 10 (10 pages maximum will be fetched from the website).
import_data.website.crawl_website=Retrieve the pages of the website
import_data.website.analyze_website=Collect the pages of a website
import_data.website.max_links=Set the maximum number of web pages to be crawled
import_data.general.choose_web_page_description=This page helps the user crawl a website. The text content of the pages will then be analyzed with the function selected by the user
import_data.general.choose_web_page_title=Crawl a website to analyze the content of the pages with nocode functions.
index.academic.citations=The algorithm for sentiment analysis has been <a href\="https\://arxiv.org/abs/1512.01818" target\="_blank">ranked the best among 24 solutions</a>. When using this function, please cite this reference\:\n<br/>\n<i>Levallois,  Clement. \u201cUmigon\: Sentiment  analysis  on  Tweets  based  on  terms  lists  and  heuristics\u201d.Proceedings of the 7th International Workshop on Semantic Evaluation(SemEval), 2013, Atlanta, Georgia.</i>
index.academic.title=Directly derived from academic research
index.acknowledgements.details=Visit the list of acknowlegdements
index.argument1=best in class data science functions which can be used without coding
index.argument2=\#free, \#no registration, \#open source
index.button.cowo=\ud83d\udd78\ufe0f transform texts into networks
index.button.gaze=\ud83d\udd27 create networks from lists
index.button.highlighter=\ud83c\udfa8 highlight text with css
index.button.link_prediction=\ud83d\udd2e link prediction in networks
index.button.networkconverter=\u267b Gephi VOSviewer converter
index.button.organic=\ud83d\udce2 detect promoted content
index.button.pdfmatcher=\ud83c\udfaf Find terms in pdf files
index.button.topics=\ud83d\udd26 find key topics in your texts
index.button.umigon=\ud83d\ude0a \ud83d\ude2c sentiment analysis
index.button.pdfregionextractor=\u2702\ufe0f extract text from pdfs
index.button.bibliocoupling=\ud83d\udcda\ufe0f bibliographic coupling
index.calltochooseafunction=choose a function\:
index.contact.details=Bug reports, improvements, suggestions... can be sent to analysis@exploreyourdata.com, or contact me <a href\="https\://twitter.com/seinecle" target\="_blank">on Twitter\!</a>
index.datapolicy=Data policy
index.datapolicy.dataannotationfunction=Regarding the function "data annotation"
index.datapolicy.dataannotationfunction.details=Data annotation consists in uploading a list of items, that annotators will annotate. This implies that the list of items is stored, as well as the list of annotators, their emails, and the annotations they make.\n<br/>\nThe designer of the task saves an email and a description of the dataset. These are stored as well.\n<br/>\nThe data (list of items, description of the list, email of the designer of the task, emails of the annotators and their annotations) is stored on a secured server base in the EU. It is not shared nor re-used for any purpose.\n<br/>\nThe data can be deleted at any point by the designer of the task.\n<br/>
index.datapolicy.forallotherfunctions=For all other functions
index.datapolicy.link=Link to this data policy written in legal terms
index.description=Free tools for data science without coding. Explore your data with click and point and no code.
index.footer.author=\u00a9 2022 Nocode functions by <a href\="https\://clementlevallois.net" target\="_blank">Clement Levallois</a>.
index.footer.languageselection=select a language for the site\: 
index.ordosometestshere=or do some tests directly here\:
index.pricing.details=The app is completely free and has no limit on usage. See <a href\="why.html">why</a>.
index.tagline=explore your data at a click
index.testorganic.analysisforFR=analysis on French text
index.testorganic.analysisforUK=analysis on English text
index.testsentimentanalysises=sentiment analysis on Spanish text
index.testsentimentanalysisfr=sentiment analysis on French text
index.testsentimentanalysisuk=sentiment analysis on English text
index.title=\ud83d\udd0e Nocode functions\: free data analysis for non coders
index.togetstarted=to get started, all you need is a file (Excel, pdf, csv, txt...) or a Google Spreadsheet containing some text.
index.togettheresults=you will see the results on the page, and download the results
link_prediction.choose_gexf_or_read_below=Choose a gexf file where new links will be predicted or read below about the methodology
link_prediction.click_to_predict=Now, click the button below to predict new links.
link_prediction.description=Free online tool using preferential attachement to predict new links in a network
link_prediction.explanation.details=<p>\nThis function is a direct application of the Gephi plugin by <a href\="https\://web.fhnw.ch/technik/projekte/i/ip519/I4DS01/index.html" target\="_blank">Marco Romanutti and Saskia Sch\u00fcler, supervised by Michael Henninger at FHNW</a>.\n</p>\n<br/>\n<p>\nTheir code is visible <a href\="https\://github.com/romanutti/gephi-plugins/tree/master/modules/LinkPrediction" target\="_blank">on Github</a>.\n</p>\n<br/>\n<p>\nThe prediction is based on <a href\="https\://en.wikipedia.org/wiki/Preferential_attachment" target\="_blank">preferential attachement</a>.\n It is limited to undirected, unweighted networks. The reasoning is simple\: the most likely link to be created is the one between two nodes which have the most neighbors, but don't have a connection yet.\n</p>\n<br/>\n<p>\nHow to interpret this link prediction? The absence of a link can mean that\:\n<br/>\n<ol>\n<li>\nThere is no potential for this link (it is not "relevant" to the nodes that would be involved)\n</li>\n<li>\nThere is a potential for this link to get created, and this potential is not actualized yet\n</li>\n<li>\nThere is a potential for the link but the two nodes choose not to actualize the link\n</li>\n</ol>\n<br/>\nThis means that "predicting" a link can address one of these three cases.\n<br/>\n<br/>\nResearch on link prediction is fascinating. Contact us if you want to implement a new link prediction method on nocodefunctions.com\!\n</p> 
link_prediction.explanation.title=Preferential attachement  - a method to predict new "probable" links in a network
link_prediction.how_many_links=How many links do you want to predict?
link_prediction.how_to_interpret.question=How to interpret this prediction value?
link_prediction.list_predicted_links=List of predicted links
link_prediction.node_prediction_value=node prediction value
link_prediction.predict_new_links=Predict new links
link_prediction.short_explanation=<p>\nThe method predicts that the nodes that have the highest <strong>product</strong> have the highest chance to get connected.\nThis assumption is called <strong><a href\="https\://en.wikipedia.org/wiki/Preferential_attachment" target\="_blank">preferential attachment</a></strong>\: the nodes that already have the most connections, tend to be the ones that create new relations.\n</p> 
link_prediction.success=\ud83d\ude9a the predictions are in\! You can see the list of predicted links below. A gexf file has been downloaded, it includes the predicted links on top of the original network.
link_prediction.tagline=\ud83d\udd2e\ufe0f\ufe0f\ufe0f Predict new links in a network
link_prediction.title=\ud83d\udd2e\ufe0f\ufe0f\ufe0f Online tool to predict new links in a network
link_prediction.warning_size=\ud83d\udea8 The network should be made of 1000 nodes or less - otherwise the computations are goint to be very slow. See below for details.
network_converter.choose_file_or_read_below=Choose a file to convert or read below about Gephi and VOSviewer.
network_converter.click_to_convert=Now, click the button below to convert it.
network_converter.convert_to_gephi=Convert to Gephi (create a gexf file)
network_converter.convert_to_vosviewer=Convert to VOSviewer json file
network_converter.creating_a_bridge.details_first_part=<p>\nNetwork data can be formatted according to different conventions\: GraphML, DL, or Pajek Net are among the most common ones.\nThis <a href\="https\://gephi.org/users/supported-graph-formats/" target\="_blank">table of network file formats</a> makes a useful (if incomplete) recap\:\n</p>
network_converter.creating_a_bridge.details_second_part=<p>\nWhat makes things impractical is that not all network viz software accept all formats. In particular\:\n<ul>\n<li>Gephi can import and export gexf files, but it does not recognize VOSviewer json network files</li>\n<li>VOSviewer can import and export VOSviewer json files, but it does not recognize gexf files</li>\n</ul>                            \n</p>\n<p>\nThe converter between gexf and VOSviewer json files offered on this page is a bridge which I hope will be found useful by the users of both software.\n</p>
network_converter.creating_a_bridge.title=Creating a bridge between Gephi and VOSviewer
network_converter.customize_legend.title=Optional\: add legends to the elements of your network.
network_converter.howto=Not sure about how to get a gexf file from Gephi? Visit this <a href\="https\://seinecle.github.io/gephi-tutorials/generated-html/simple-project-from-a-to-z-en.html\#_export_a_network_as_a_web_visualization" target\="_blank">detailed tutorial on how to go from Gephi to a web visualization with VOSviewer</a>.
network_converter.items.question=What do the "items" (or nodes, or agents...) in your network represent? Give it a short name
network_converter.limit_to_500_nodes.details=<p>\n  While Gephi is made for small and very large networks, VOSviewer is made for networks up to about 500 nodes. 300 nodes is even preferable. Above this size, the visualization becomes harder to read and the operations become very slow.\n  </p>\n  <br/>\n  <p>\n  What if your network is bigger than 500 nodes? Nocodefunctions helps you\: in the gexf file, it will select the 500 nodes <strong>in the edges that have the larger weight</strong>. The other nodes will be filtered out. This should produce a smaller network which still gives a helpful view of the original, complete network.\n</p>
network_converter.limit_to_500_nodes.question=What about the limit to 500 nodes?
network_converter.links.question=What do the "links" (or edges, or bonds...) in your network represent? Choose a short name
network_converter.links_strength.question=What do the "link strength" (or weight) in your network represent? Choose a short description.
network_converter.option1=Option 1\: convert a Gephi gexf file to a VOSviewer json file [and optionally, share the file immediately as a web visualization]
network_converter.option2=Option 2\: convert a VOSviewer json file to a Gephi file (.gexf format)
network_converter.share_vosviewer_publicly.details=<p>When you make the visualization public, a permanent link is generated. You can bookmark it and share the visualization.</p>\n<p>More information in this <a href\="https\://seinecle.github.io/gephi-tutorials/generated-html/simple-project-from-a-to-z-en.html\#_3_public_or_private_web_visualization_how_to_manage" target\="_blank">Gephi tutorial</a>.</p>\n
network_converter.share_vosviewer_publicly.question=Make the VOSviewer visualization shareable on the web with a public url?
network_converter.tagline=Convert files between Gephi and VOSviewer
network_converter.title=Online tool to convert gexf files to vosviewer json format, and back
network_converter.warning_not_gephi_file=\u26a1 The file should be a <strong>.gexf file</strong>, not a <strong>.gephi file</strong>\!\n<a href\="https\://seinecle.github.io/gephi-tutorials/generated-html/simple-project-from-a-to-z-en.html\#_export_a_network_as_a_web_visualization" target\="_blank">See all the details here</a>\n<br/>\n\ud83d\udea8 The network should be made of 500 nodes or less - otherwise the online visualization will be impossible to read. See below for details.\n<br/>\n<br/>
organic.description=100% free online tool to identify organic content on Twitter, Instagram and social media. Detect promoted \ud83d\udce2 vs spontaneous \ud83c\udf3f comments on social media.
organic.details=This function classifies your texts in two categories\:<ul><li><strong>organic</strong>\: when the text is written in a style which is natural, personal, individual.</li><li><strong>promoted</strong>\: when the text is written in a style which is corporate, sponsored, artificial.</li></ul>It works best on <strong>social media</strong> such as tweets for Twitter, comments on Instagram posts and other very short texts in English and French.<br/>Born in 2020, this tool is under continuous development.
organic.general.argument1.details=The tool is programmed with Java which performances are similar too, or better than <strong>Python</strong>. It does not rely on <a href\="https\://en.wikipedia.org/wiki/Part-of-speech_tagging" target\="blank">part-of-speech tagging (POS tagging)</a>, which makes it even faster. Parallel computing is used in subfunctions and great care has been given to performance.
organic.general.argument1.title=\ud83d\ude80 Fast and performant
organic.general.argument2.details=<p>This tool identifies markers of <u>corporate speak</u>. This characterization is not clearly defined in the academic literature. The intent is to provide content managers and analysts a tool which allows them to filter out content which does not represent a <strong>genuine voice of the customer</strong>, such as\:</p><br/><ul><li><strong>calls to action</strong>\: "VOTE", "BUY", "PLAY", ...</li><li><strong>promotional invitations</strong>\: "hottest deals", "give away", ...    </li><li><strong>expressions of opinion which are crafted by a communication specialist</strong>, as hinted by the specific terms used\: "unveiled", "stoked to", "reinvents" ...  </li></ul><br/>This is work in progress and we welcome your feedback and suggestions (analysis@exploreyourdata.com). We believe this function is already extremely useful, helping analysts specializing in opinion mining clean their dataset from the content which does not originate from individuals / customers but from corporations and communication officers (check our <a href\="../umigon/sentiment_analysis_tool.html">function for sentiment analysis</a>). This will make their measurement more reliable, especially for opinion mining.
organic.general.argument2.title=Organic vs promoted content\: further considerations
organic.general.model_long_description=<p>The principles followed by the tool are similar to <a href\="../umigon/sentiment_analysis_tool.html">the function for sentiment analysis</a>, except for the rules to be applied. The tool follows these steps\:</p>\n<ol>\n<li>check on the length of the text\: if it is just a couple of words short, it will not be classified</li>\n<li>removal of urls, removal of content in quotes, normalization of apostrophs</li>\n<li>two versions of the text are established\: one where all the accents and special characters are removed, and one where they are retained. All the following steps will apply to both versions of the text.</li>\n<li>check on <strong>emojis, emoticons and onomatopeia</strong>. Do not preprocess your text to remove them, they provide useful information on sentiment\!</li>\n<li>check on hashtags, if any</li>\n<li>decomposition of the text in n-grams up to four-grams</li>\n<li> for each n-gram\:\n<ul>\n<li>skip it if it belongs to a pre-established list of stop words</li>\n<li>check for repeated characters and remove them as necessary (<code>yeeeahhh\!</code> becomes <code>yeah\!</code>)</li>\n<li>check if the n-gram is contained in the pre-established list of vocabulary / expressions / style signalling "corporate speech". If so, the corresponding rule is applied.</li>\n</ul>\n</li>\n<li>final decision, based on the results of the previous steps.</li>\n</ol>
organic.general.model_short_description=The function examines each term of the text and applies a series of rules (in this context, is the term organic or promoted?). It also considers <strong>emojis</strong>, punctuation, <strong>hashtags</strong>, capitalized words... to determine the result.
organic.general.soundsorganic=natural / genuine voice
organic.general.soundspromoted=corporate / sponsored voice
organic.general.tone_of_voice=tone of voice
organic.tagline=Analysis of organic voice of customer for Twitter, Instagram and beyond
organic.title=\ud83d\udce2 Organic listening of the voice of customer\: free and online tool.
pdfmatcher.pdfmatcher.tagline=No special paramater for this function. Click the button to continue.
pdfmatcher.results.tagline=Match terms of interest in pdf files - results
pdfmatcher.results.title=Match terms of interest in pdf files - results
pdfmatcher.tool.description=This is a free and online tool to match words in your pdf files
pdfmatcher.tool.nb_words_for_context=how many words before and after the target should be retrieved for context?
pdfmatcher.tool.select_search_word=select the word or phrase to be searched in the pdf files
pdfmatcher.tool.error.parentheses=error: it seems that a parenthesis is missing
pdfmatcher.tool.error.quotes=error: it seems that a quotation mark is missing
pdfmatcher.tool.type_of_context=How to show the context of the matching word: surrounding lines, or surrounding words?
pdfmatcher.tool.type_of_context_description=This parameter controls how the matching words will be displayed. If you choose "surrounding words", the result will show the matching word and the few words that are before and after it in the text. If you choose "surrounding lines", the result will show more context, before and after the matching word.
pdfmatcher.tool.surrounding_lines=surrounding lines
pdfmatcher.tool.surrounding_words=surrounding words
pdfmatcher.tool.start_of_page=start of page
pdfmatcher.tool.end_of_page=end of page
pdfmatcher.tool.search_case_sensitive=should the search be case sensitive?
pdfmatcher.tool.tagline=\ud83c\udfaf Identify the pdf files that contain a word of interest, with context
pdfmatcher.tool.title=\ud83c\udfaf Select a word as input and find it in the pdf files your provide
sidebar.copypaste_incorrect=copy paste here the incorrect phrasing
sidebar.report_bad_translation=report an error in translation?
sidebar.report_error_in_app=report an error in the app
sidebar.suggestion_new_feature=do you have a suggestion for a new feature?
sidebar.write_better_phrasing=write your suggestion for a better phrasing
support.description=Get support through email, Twitter, Whatsapp or over the phone
support.phonecall.details=Offering support over the phone is an experiment, <a href\="https\://news.ycombinator.com/item?id\=28594313" target\="_blank">based on this story</a>. Let's see where it leads.
support.phonecall.title=Phone call
support.tagline=Any issue or suggestion? Get in touch\!
support.title=Get support and troubleshooting assistance
topics.results.title=Identify topics in your texts - results
topics.topics.parameter_precision.explanation=50 is the default. Choose a lower value to find <strong>more and smaller</strong> topics, and choose a higher value to find <strong>fewer and larger</strong> topics\:<br/><br/> <small>lower values \=&gt; find many "smaller" topics.</small><br/>
topics.topics.parameter_stopwords.explanation=Remove 'scientific' stopwords\: words which are typical of the academic discourse and that do not carry specific information value (texts in English or French only). The full list is available <a href\="https\://github.com/seinecle/Stopwords/tree/master/src/main/java/net/clementlevallois/stopwords/resources" target\="_blank">here</a>.
topics.topics_extraction_tool.argument1.details=This function identifies automatically the key topics in a text, an operation called <strong>topic extraction</strong> or <strong><a href\="https\://en.wikipedia.org/wiki/Topic_model" target\="_blank">topic modelling</a></strong>. It analyzes the text line by line and determines groups of words and expressions which tend to <strong>cluster</strong> together, forming topics.<br/>It works on texts written in a large variety of languages (including texts in non Latin alphabet). The function follows the principles of unsupervised learning, which is a type of <strong>machine learning</strong>.<br/><br/>If you use this function in an academic context (research or studies), you must reference it in your bibliography\:<br/><br/>Benabdelkrim, M., Levallois, C., Savinien, J., &amp; Robardet, C. (2020). Opening Fields\: A Methodological Contribution to the Identification of Heterogeneous Actors in Unbounded Relational Orders. M@n@gement, 23(1), 4-18.
topics.topics_extraction_tool.argument1.title=Topic extraction - automate the analysis of key topics in your texts
topics.topics_extraction_tool.argument2.details=The technology includes a "precision" parameter to control finely if you need big ("macro") topics to be found, or instead if you prefer to identify many "micro" (smaller) topics.
topics.topics_extraction_tool.argument2.title=Innovative\: control how "big" or "micro" the topics will be
topics.topics_extraction_tool.argument3.details=<p><strong>Structure and format of the text</strong>\: Topic extraction works by detecting pairs of terms which appear on the same line of text. So you should be careful about how your text is formatted. Ideally, it should be made of relatively short paragraphs, each on one line. If you are using an Excel file, each paragraph or significant block of text should appear on a different row.<br/><br/><strong>Volume of text</strong>\: topics are found by measuring frequencies\: which pair of terms tend to co-occur most often? For this to work, the text should be sufficiently long so that these counts are meaningful. The longer the text, the better. Texts of at least 5,000 words seem a good start.</p>
topics.topics_extraction_tool.argument3.title=Tips and Tricks for Effective Results in Subject Detection
topics.topics_extraction_tool.argument4.title=How to define the number of subjects to find? Is this a good thing?
topics.topics_extraction_tool.description=100% free online topic extraction tool \ud83d\udd26 for non coders, no registration required. Import your text from Twitter in csv, Excel and Google spreadsheets. Performance is as good as or better than Python tools. Run the analysis in one click. Download your results in Excel.
topics.topics_extraction_tool.excel_export_details=This Excel file contains the list of keywords per topics. NEW\: it also contains the list of the text lines that were contained in the document you uploaded. For each line, you can now see the three topics that match. It is useful when you want to ask\: which line or document is in this topic?
topics.topics_extraction_tool.model_long_description.details=<p>The principles followed by the tool are described in this academic publication studying <a href\="https\://management-aims.com/index.php/mgmt/article/view/4245" target\="_blank">how to find communities and topics on Twitter</a>. The technology follows these steps\:</p><ol><li>cleaning of the text\: flatten to ASCII, removal of urls, removal of punctuation signs.</li><li>lemmatization.</li><li>decomposition of the text in n-grams up to four-grams, removal of less relevant n-grams. This step is identical to the one followed by the <a href\="../umigon/sentiment_analysis_tool.html">function for sentiment analysis</a></li><li>count of cooccurrences\: which pairs of n-grams tend to appear frequently in the same lines of the text?</li><li>the list of cooccurring n-grams is used to create a network\: it is made of the most frequent n-grams. Two n-grams are connected if they are frequently cooccurring.</li><li>a community detection algorithm is applied to the network\: the Louvain algorithm, which is fast and very effective.</li><li>the parameter chosen by the user is applied\: a large value will detect a few big communities. A small value will detect many little communities.</li><li>each community (or cluster) in the network is a topic. The list of key terms in the topic are the n-grams contained in the cluster.</li></ol>
topics.topics_extraction_tool.model_short_description.details=The function identifies pairs of terms in each line of the text. These pairs are called cooccurrences. Aggregating all pairs of terms, a network of terms is constructed. The network is cut into subregions, and each subregion corresponds to a topic.
topics.topics_extraction_tool.tagline=\ud83d\udd26 Free topic extraction tool for documents and social media
topics.topics_extraction_tool.title=\ud83d\udd26 Topic extraction tool, free and online. Click and point and no code.
umigon.general.negativesentiment=negative sentiment
umigon.general.neutralsentiment=neutral sentiment
umigon.general.positivesentiment=positive sentiment
umigon.general.sentiment=sentiment
umigon.results.tagline=Analysis of sentiments for social media\: results
umigon.sentiment_analysis_tool.api.explanation-lang.details=choose the language of the explanations. The parameter is a two-letter code for the language ("zh" for Chinese, for instance)
umigon.sentiment_analysis_tool.api.explanation.details=this parameter has two values\: "on" for rich explanations, or "off" if you just need the result without explanations
umigon.sentiment_analysis_tool.api.output-format.details=choose between 3 values\: "plain", "html" or "json"
umigon.sentiment_analysis_tool.api.text-lang.details=the language of the text to anlayze. "en" for English, "fr" for French or "es" for Spanish
umigon.sentiment_analysis_tool.api.text.details=the text to analyze
umigon.sentiment_analysis_tool.api.try_with_parameters=You can modify these parameters in the url\:
umigon.sentiment_analysis_tool.argument1.details=This function performs <strong><a href\="https\://en.wikipedia.org/wiki/Sentiment_analysis" target\="_blank">sentiment analysis</a></strong>, also called opinion mining. It analyzes the text and determines whether the sentiment is neutral, positive or negative.<br/>It works best on <strong>social media</strong> such as tweets for Twitter, comments on Instagram posts and other very short texts in English or French. In a comparison with 23 alternatives, this tool was found to be the best <a href\="https\://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-016-0085-1" target\="blank">tool for sentiment analysis on social media</a>.<br/>Born in 2012, this tool is under continuous development.<br/><br/>If you use this function in an academic context (research or studies), you must reference it in your bibliography\:<br/><br/>Levallois, Clement. "Umigon\: Sentiment analysis on Tweets based on terms lists and heuristics". Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval), 2013, Atlanta, Georgia.
umigon.sentiment_analysis_tool.argument1.title=Analysis of sentiments for Twitter, Instagram and beyond
umigon.sentiment_analysis_tool.argument3.details=The function is programmed in Java. His code is accessible <a href\="https\://github.com/stars/seinecle/lists/sentiment-emotion-analysis" target\="_blank">freely on Github</a>. Its performance is excellent because it does not rely on <a href\="https\://en.wikipedia.org/wiki/Part-of-speech_tagging" target\="_blank">part-of-speech taggging (POS tagging)</ a>, which makes it fast. <a href\="https\://en.wikipedia.org/wiki/Concurrent_computing" target\="_blank">Concurrent computing</a> techniques are used in sub-functions and great attention has been paid to overall performance. 
umigon.sentiment_analysis_tool.argument3.title=Fast and efficient
umigon.sentiment_analysis_tool.argument6.details=<p>Some tools provide a scoring to express the strength of the sentiment\: a large value for a very positive sentiment, and a very low value for a negative sentiment. Zero represents a neutral sentiment. In my experience, these scorings are not super reliable, except for the obvious cases. "Horrible" will score really low, and "wonderful" will score really high. But in the middle, things are less straightforward and the scorings are much harder to interpret - I would not advise to rely on them. A more promising road would be to introduce <strong>emotions</strong> to tease out the finer nunances of sentiment, beyond the positive / neutral / negative categories. Drop an email at analysis@exploreyourdata.com if you are interested in this direction of research.</p>
umigon.sentiment_analysis_tool.argument6.title=Scoring, percentage and emotions?
umigon.sentiment_analysis_tool.argument7.details=<p>This tool identifies subjective markers of <u>sentiment</u>, NOT positive or negative <u>factual statements</u>. To give an example\:</p><br/><ul><li>"<code>This country is at war</code>" -> it is classified as <strong>NEUTRAL</strong>, even if a country at war is "objectively" or "factually" not a positive thing.</li><li>"<code>War is horrible \:(</code>" -> it is classified as <strong>NEGATIVE</strong> because the term "horrible" and the emoji are subjective markers of a negative sentiment.</li><li>"<code>War of the sexes is an exciting research topic\!</code>" -> it is classified as <strong>POSITIVE</strong> because the term "exciting" is a subjective marker of a positive sentiment.</li></ul><br/>We believe this approach makes sentiment analysis reliable and really unique in the landscape of tools for opinion mining and sentiment analysis. Ready to try it?\#TOPICS
umigon.sentiment_analysis_tool.argument7.title=Positive, Neutral, and Negative Feelings\: Additional Considerations
umigon.sentiment_analysis_tool.model_long_description.details=<p>The principles followed by the tool are described in this academic publication about <a href\="https\://aclanthology.org/S13-2068/" target\="_blank">Umigon, published in the anthology of the Association fo Computational Linguistics</a>. The tool follows these steps\:</p><ol><li>check on the length of the text\: if it is just a couple of words short, it will not be classified</li><li>removal of urls, removal of content in quotes, normalization of apostrophs</li><li>two versions of the text are established\: one where all the accents and special characters are removed, and one where they are retained. All the following steps will apply to both versions of the text.</li><li>check on <strong>emojis, emoticons and onomatopeia</strong>. Do not preprocess your text to remove them, they provide useful information on sentiment\!</li><li>check on hashtags, if any</li><li>decomposition of the text in n-grams up to four-grams</li><li> for each n-gram\:<ul><li>skip it if it belongs to a pre-established list of stop words</li><li>check for repeated characters and remove them as necessary (<code>yeeeahhh\!</code> becomes <code>yeah\!</code>)</li><li>check if the n-gram is contained in the pre-established list of potentially positive words. If so, the corresponding rule is applied. Most often the rule is as simple as "a positive word gives a positive sentiment to the text", but more complex rules are also included of course.</li><li>check if the n-gram is contained in the pre-established list of potentially negative words. Same logic applies</li></ul></li><li>final checks\: detection of moderators in the sentence ("but", "however", "even if", etc.). Positive or negative values placed before or after these moderators are kept or get deleted.</li><li>final decision following complex rules, based on the results of the previous steps.</li></ol>
umigon.sentiment_analysis_tool.model_short_description.details=The function examines each term of the text and applies a series of rules to determine the effect on the sentiment. It also systematically considers <strong>emojis</strong>, punctuation, <strong>hashtags</strong>, variations in spelling, capitalized words... to determine the sentiment.
umigon.sentiment_analysis_tool.tagline=\ud83d\ude0a \ud83d\ude2c Free sentiment analysis tool for social media in English, French and Spanish
umigon.sentiment_analysis_tool.title=\ud83d\ude0a \ud83d\ude2c Free sentiment analysis tool for social media in English, French and Spanish
validation.email_not_valid=email is not valid
who.argument1.details=<p>Hi\! I am <a href\="https\://em-lyon.com/en/clement-levallois/briefly" target\="_blank">a professor</a> based in Paris, with a passion for extracting information from social media and networks. Twitter and <a href\="https\://gephi.org" target\="_blank">Gephi</a> are my favorite playgrounds. I publish studies in <a href\="https\://scholar.google.fr/citations?hl\=en&amp;user\=r0R0vekAAAAJ" target\="_blank">academic journals</a>.</p><p>You can find me discussing on <a href\="https\://www.facebook.com/groups/gephi" target\="_blank">the Facebook group for Gephi</a> or commenting tech and academic news <a href\="https\://twitter.com/seinecle" target\="_blank">on Twitter</a> or discussing <a href\="https\://www.linkedin.com/in/levallois/" target\="_blank">professional news on LinkedIn</a>. Oh, and this is <a href\="https\://clementlevallois.net" target\="_blank">my website</a>. See you there\!</p>
who.argument2.details=I have dedicated a page to this question, <a href\="why.html">follow the link\!</a>
who.argument2.title=Why creating nocode functions?
who.description=Cl\u00e9ment Levallois, academic and web app developer
who.tagline=Hello\! I am Cl\u00e9ment Levallois
who.title=Who is behind nocode functions?
why.argument1=The fundamental motivation
why.argument1.details=<p>\nAs an academic interested in data mining with social media and social networks, I have shared the results of my studies in articles <a href\="https\://scholar.google.fr/citations?hl\=en&amp;user\=r0R0vekAAAAJ" target\="_blank">published in scientific journals</a>. With nocode functions, <strong>I wish to reach a wider audience by offering free, nocode versions of the most useful functions I have been using in my research</strong>.\n</p>\n<br/>\n<p>\nIn the past few years, I have made several attempts at creating pieces of software that would do just that. But I was not experienced enough, and probably too impatient\: the apps were unfinished and hard to maintain. Nocode functions is different\: I take the time to develop it in the best manner, and <a href\="https\://nocodefunctions.com/blog/long-game/" target\="_blank">I embark for a journey of 10 years and more\!</a>\n</p>
why.argument2=Why is it free?
why.argument2.details=<p>Developing nocode functions represents a significant amount of work, which I accomplish in my free time. I don't charge for it, so that it finds a wider audience (including students, journalists, hobbyists...). In return, I hope to use it to deploy the new functions I will create in the course of my academic research, and I hope it will benefit my studies\: the user feedback on the functions will help me refine them and make them more robust. Hopefully, a community of users will grow and will generate interesting ideas for new developments as well\!</p><br/><p>Second, depending on the interest of the users, I consider developing API versions for high volume, high availability versions of the functions, typically for professional use by enterprises, not individuals. These APIs would not be free as significant server costs would be involved.</p>
why.description=Nocode functions is developed to remain free and accessible to all
why.tagline=Why has nocode functions been made?
why.title=Why is nocode functions developed?
topics.topics_extraction_tool.gexf_export_details=You can also download this gexf file, if you know how to use it with <a href="https://gephi.org" target="_blank">Gephi</a>. The file contains the network of all 2,000 most frequent words contained in the file that you uploaded. It is useful to explore the topics in finer details.
#Lemmatization
general.nouns.lemmatization=Lemmatization
general.message.lemmatization_explanation=Words can have many variations. In many languages, singular and plural nouns or verbs in the present and past tense have slightly different forms. The operation which consists in removing these different forms is called lemmatization. It is useful to obtain results where we see the same word just once, not all the forms of the same word which were present in the text you analyze. However sometimes, the operation of lemmatization is not performed accurately. It truncates words in an incorrect way, and as a result the analysis can produce words that have an incorrect spelling near their end. This is why, even if the operation of lemmatization is applied by default, you can disable it here.
general.verbs.lemmatize=lemmatize
general.nouns.accents_removal=Removal of accents and diacritics
general.message.accents_removal_explanation=By default, the accents and diacritical marks in your texts are preserved (not removed). With this option, you can choose to remove them. In some languages and for some use cases, it can make the final result cleaner. In French for example, removing accents can help merge the terms '\u00e9limin\u00e9' and 'elimine', which can be a desirable output. In other languages, removing accents and diacritics can be a bad idea. For example in Spanish, it would turn "a\u00f1o" into "ano", which has a different meaning.
general.verbs.remove_accents=Remove accents
network_converter.description=Convert gexf files from Gephi to the VOSviewer json format. Export VOSviewer files to Gephi.
spatialize.description=Spatialize very large gexf network files for Gephi
spatialize.select_duration_in_seconds=Select the duration for running the spatialization (in seconds)
spatialize.click_below_to_spatialize=Click the button below to start the spatialization
index.button.spatialize=\ud83d\ude85 spatialize large gexf files quickly
index.button.mapsofscience=\ud83d\uddfa Maps of science
spatialize.title=Spatialize a large gexf file, quickly
spatialize.launch_spatialization=Launch the spatialization
spatialize.explanation=This function takes a gexf file as an input. It applies a "Force Atlas 2" layout to it, in a way which is much faster than what you could achieve when using Gephi. This is especially useful when the graph is large.
pdfmatcher.tool.complex_query_allowed=New! Complex search queries are now authorized. Example:
pdfregionextractor.tool.description=Free tool to extract text from a specific region in pdf files, fast and respectful of your data
pdfregionextractor.tool.title=Extract text from a specific region in pdf files
pdfregionextractor.tool.upload_sample=Upload a sample pdf to indicate where is the region where the text should be be extracted
pdfregionextractor.tool.all_pages_or_selected_long=should the region be extracted on all pages or just on the selected page?
pdfregionextractor.tool.all_pages_or_selected_short=on all pages
pdfregionextractor.tool.region_on_this_page=region to extract will be set on this page only
pdfregionextractor.tool.confirm_region=confirm the region and upload all your pdfs to be extracted
import_data.pdfregion.title=Upload all the pdfs for text extraction
import_data.pdfregion.description=The region where the text will be extracted has been defined previously. Now, you can upload the pdfs for text extraction on this region.
import_data.pdfregion.proceed=Proceed to the text extraction
pdfregionextractor.results.title=Download the extracted text as an Excel file
pdfregionextractor.results.tagline=Results available for download
pdfregionextractor.tool.description_long_2=You start here by uploading a sample pdf and use the mouse to select the zone where the text should be extracted. Also, choose whether this zone is on a specific page or if this zone should be extracted on all pages.
pdfregionextractor.tool.description_long_3=In the next page, you will then upload all your pdfs and the application will extract the text from them, but only in the zone you predefined. If the usage of this function remains unclear, get in touch at analysis@exploreyourdata.com
pdfregionextractor.tool.description_long_1=This new tool has a very specific usage: for users who have many pdfs which follow the same format, and who need to extract the text from a precise region, always the same, in all these pdfs.
pdfregionextractor.tool.description.video_tutorial=You can watch this very short video tutorial on how to use the function.
general.message.read_this_tutorial=Read this simple and helpful tutorial
bibliocoupling.description=Create a network of publications based on the common documents they cite. Just upload a list of titles and the tool fetches the citations on OpenAlex and creates the network, that you can visualize and download.
bibliocoupling.title=Give a list of publication titles, get a network based on how many common references they cite.
bibliocoupling.tagline=\ud83d\udcda\ufe0f\ufe0f\ufe0f Biblio coupling: Visualize a network of articles based on their shared citations
bibliocoupling.results.tagline=\ud83d\udcda\ufe0f\ufe0f\ufe0f Biblio coupling\: create citation networks from a list of article's titles
bibliocoupling.results.title=\ud83d\udcda\ufe0f\ufe0f\ufe0f Biblio coupling\: create citation networks from a list of article's titles
bibliocoupling.results.long_explanation=Two publication titles are connected in the graph if they share a common citation. Citation data has been fetched from OpenAlex.org
bibliocoupling.info.startopenalexdataretrieval=starting retrieving citation data from openalex.org. About 3 publications are processed per second.
bibliocoupling.info.openalexdataretrieved=finished retrieving citation data from openalex.org
bibliocoupling.info.startsim=starting measuring similarities between publications based on their citations
general.nouns.article_title=upload article titles
general.nouns.article_doi=upload dois
general.message.doi_as_link_or_not=if you select DOIs (digital object identifiers), they can be simple dois or the format with full http link.
general.message.example_valid_dois=examples of valid formats for digital object identifiers:
bibliocoupling.data_description=The data you provide is a list of titles OR DOIs of publications. In your file, there should be one item (title or DOI) per line.
general.message.help_nocodefunctions_referral_form=if you have a moment: nocodefunctions needs your help!
general.message.click_here=click here
index.datapolicy.forallotherfunctions.details=The policy is simple: the data you upload is never stored, shared or reused. In practice, it is sent securely from this website with SSL (https) \ud83d\udd12 to a secure server. There, it is immmediately analyzed. Then, it is destroyed when your session ends, which is when you close the web page.
umigon.sentiment_analysis_tool.description=Free online sentiment analysis tool without coding. Sentiment extraction for social media or text in csv, Excel and pdf files. Performance is as good as or better than machine learning frameworks. Run the analysis in one click. Download your results in Excel.
general.message.text_in_bulk=Plain text (txt or pdf files). Supports a very large number of files.
topics.topics_extraction_tool.argument4.details=\ called the <a href="https://en.wikipedia.org/wiki/K-means_clustering" target="_blank">"k-means"</a>. With it, the user decides how many topic should be found in the text, and then the algorithms finds these topics.</p>\n<p>This approach can make sense when we know in advance how many topics there are in the text. But what is the point of topic detection if we know the topics already? \ud83e\udd14</p>\n<p>In nocode functions, the number of topics to be found is not predetermined. The analyst wil learn a lot by discovering how many topics the algorithm can find in the text, without a preset limit. The analyst remains fully in control thanks to the precision parameter, which helps tune the algorithm to find more or less topics - but always with a degree of freedom on the exact number.</p>\n<p>50 is the default. Choose a lower value to find <strong>more and smaller</strong> topics, and choose a larger value to find <strong>less and bigger</strong> topics:</p>\n<br/>\n<small>smaller values => find many 'smaller' topics.</small>\n<br/>
