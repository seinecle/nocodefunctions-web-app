general.verbs.compute=compute
general.verbs.signal_error=signal an error
general.verbs.confirm_options=confirm your options

general.small_words.or=or

general.message.should_be=should be

general.nouns.parameters=parameters
general.nouns.academic_stopwords=stopwords from the academic discourse
general.nouns.topics=topics
general.nouns.topic=topic
general.nouns.key_terms=key terms
general.message.use_it_directly_by_selecting_a_data_source=Use it directly by selecting the data to be analyzed:
general.message.text_in_bulk=Plain text (txt or pdf files)
general.message.text_structured=Structured text in columns or tables (csv or Excel files)
general.message.new_api_available=New: API access now available
general.message.try_it_just_click_on_link=Try it, just click on the link:
general.message.or_read_explanations_below=... or read below about what it does, and how it works:
general.message.import_your_data_get_results_example=Import your data, get the results: an example
general.message.language_of_text_to_analyze=Select which is the language of the text:
general.message.wait_and_authorize_popup=Wait... and authorize pop up windows
general.message.get_in_touch_if_need_support_new_language=(get in touch if you would need a new language to be supported)
general.message.remove_science_stopwords=Remove 'science' stopwords
general.message.providing_own_stopwords.title=providing your own stopwords
general.message.providing_own_stopwords.details1=Upload a list of stopwords. It must be a .txt file with one word per line.
general.message.providing_own_stopwords.details2=Select this box if this list should replace (rather than add up to) the default stopword list.
general.message.providing_own_stopwords.details3=Select this box if you agree these stopwords can be shared and re-used to improve the app for everyone \ud83d\ude4f.

general.title.model_short_description.title=The model - short description
general.title.model_long_description.title=The model - long description
general.title.if_you_need_more_parameters=If you need more parameters \ud83e\udd13

general.languages.arabic= Arabic
general.languages.bulgarian= Bulgarian
general.languages.catalan= Catalan
general.languages.danish= Danish
general.languages.dutch= Dutch
general.languages.english= English
general.languages.french= French
general.languages.german= German
general.languages.greek= Greek
general.languages.italian= Italian
general.languages.norwegian= Norwegian
general.languages.polish= Polish
general.languages.portuguese= Portuguese
general.languages.russian= Russian
general.languages.spanish= Spanish

header.menu.home=Home
header.menu.whodevelopsit=Who develops it?
header.menu.why=Why?
header.menu.getsupport=Get support
header.menu.blog=Blog
header.menu.pricing=Pricing
header.menu.acknowledgements=Acknowledgements

index.title=\ud83d\udd0e Nocode functions: free data analysis for non coders
index.description=Free tools for data science without coding. Explore your data with click and point and no code.
index.tagline=explore your data at a click
index.argument1=best in class data science functions which can be used without coding

index.button.umigon=\ud83d\ude0a \ud83d\ude2c sentiment analysis
index.button.organic=\ud83d\udce2 detect promoted content
index.button.cowo=\ud83d\udd78\ufe0f transform texts into networks
index.button.topics=\ud83d\udd26 find key topics in your texts
index.button.networkconverter=\u267b Gephi VOSviewer converter
index.button.link_prediction=\ud83d\udd2e link prediction in networks

index.ordosometestshere=or do some tests directly here:

index.testsentimentanalysisuk=sentiment analysis on English text
index.testsentimentanalysisfr=sentiment analysis on French text
index.testsentimentanalysises=sentiment analysis on Spanish text
index.testorganic.analysisforUK=analysis on English text
index.testorganic.analysisforFR=analysis on French text

index.togetstarted= to get started, all you need is a file (Excel, pdf, csv, txt...) or a Google Spreadsheet containing some text.
index.togettheresults= you will see the results on the page, and download the results

index.datapolicy=Data policy
index.datapolicy.dataannotationfunction=Regarding the function "data annotation"
index.datapolicy.dataannotationfunction.details=Data annotation consists in uploading a list of items, that annotators will annotate. This implies that the list of items is stored, as well as the list of annotators, their emails, and the annotations they make.\n<br/>\nThe designer of the task saves an email and a description of the dataset. These are stored as well.\n<br/>\nThe data (list of items, description of the list, email of the designer of the task, emails of the annotators and their annotations) is stored on a secured server base in the EU. It is not shared nor re-used for any purpose.\n<br/>\nThe data can be deleted at any point by the designer of the task.\n<br/>
index.datapolicy.forallotherfunctions=For all other functions
index.datapolicy.forallotherfunctions.details=The policy is simple: the data you upload is never stored, shared or reused. In practice, it is sent securely from this website with SSL (https) \ud83d\udd12 to a secure server. There, it is immmediately analyzed. Then, it is destroyed when you close the web page. As simple as this. If you prefer to keep all your data on your own computer anyway, you can try the (unmaintained) desktop app \ud83d\udcbb (PC and Linux only) <a href="https://seinecle.github.io/nocodeapp-mods/" target="_blank">here</a>.

index.datapolicy.link=Link to this data policy written in legal terms

index.academic.title=Directly derived from academic research
index.academic.citations=The algorithm for sentiment analysis has been <a href="https://arxiv.org/abs/1512.01818" target="_blank">ranked the best among 24 solutions</a>. When using this function, please cite this reference:\n<br/>\n<i>Levallois,  Clement. \u201cUmigon: Sentiment  analysis  on  Tweets  based  on  terms  lists  and  heuristics\u201d.Proceedings of the 7th International Workshop on Semantic Evaluation(SemEval), 2013, Atlanta, Georgia.</i>

index.pricing.details=The app is completely free and has no limit on usage. See <a href="why.html">why</a>.

index.contact.details=Bug reports, improvements, suggestions... can be sent to analysis@exploreyourdata.com, or contact me <a href="https://twitter.com/seinecle" target="_blank">on Twitter!</a>

index.acknowledgements.details=Visit the list of acknowlegdements

index.footer.author=\u00a9 2022 Nocode functions by <a href="https://clementlevallois.net" target="_blank">Clement Levallois</a>.
index.footer.languageselection=select a language for the site: 

why.title=Why is nocode functions developed?
why.description=Nocode functions is developed to remain free and accessible to all
why.tagline=Why has nocode functions been made?
why.argument1=The fundamental motivation
why.argument1.details=<p>\nAs an academic interested in data mining with social media and social networks, I have shared the results of my studies in articles <a href="https://scholar.google.fr/citations?hl=en&amp;user=r0R0vekAAAAJ" target="_blank">published in scientific journals</a>. With nocode functions, <strong>I wish to reach a wider audience by offering free, nocode versions of the most useful functions I have been using in my research</strong>.\n</p>\n<br/>\n<p>\nIn the past few years, I have made several attempts at creating pieces of software that would do just that. But I was not experienced enough, and probably too impatient: the apps were unfinished and hard to maintain. Nocode functions is different: I take the time to develop it in the best manner, and <a href="https://nocodefunctions.com/blog/long-game/" target="_blank">I embark for a journey of 10 years and more!</a>\n</p>

why.argument2=Why is it free?
why.argument2.details=<p>\
    Developing nocode functions represents a significant amount of work, which I accomplish in my free time. \
    I don't charge for it, so that it finds a wider audience (including students, journalists, hobbyists...). \
    In return, I hope to use it to deploy the new functions I will create in the course of my academic research, and I hope it will benefit my studies: the user feedback on the functions will help me refine them and make them more robust. \
    Hopefully, a community of users will grow and will generate interesting ideas for new developments as well!\
    </p>\
    <br/>\
    <p>\
    Second, depending on the interest of the users, I consider developing API versions for high volume, high availability versions of the functions, typically for professional use by enterprises, not individuals. \
    These APIs would not be free as significant server costs would be involved.\
    </p>

who.title=Who is behind nocode functions?
who.description=Cl\u00e9ment Levallois, academic and web app developer
who.tagline=Hello! I am Cl\u00e9ment Levallois
who.argument1.details=<p>\
    Hi! I am <a href="https://em-lyon.com/en/clement-levallois/briefly" target="_blank">a professor</a> based in Paris, with a passion for extracting information from social media and networks. Twitter and <a href="https://gephi.org" target="_blank">Gephi</a> are my favorite playgrounds. I publish studies in <a href="https://scholar.google.fr/citations?hl=en&amp;user=r0R0vekAAAAJ" target="_blank">academic journals</a>.\
    </p>\
    <p>\
    You can find me discussing on <a href="https://www.facebook.com/groups/gephi" target="_blank">the Facebook group for Gephi</a> or commenting tech and academic news <a href="https://twitter.com/seinecle" target="_blank">on Twitter</a> or discussing <a href="https://www.linkedin.com/in/levallois/" target="_blank">professional news on LinkedIn</a>. Oh, and this is <a href="https://clementlevallois.net" target="_blank">my website</a>. See you there!\
    </p>

who.argument2.title=Why creating nocode functions?
who.argument2.details=I have dedicated a page to this question, <a href="why.html">follow the link!</a>

support.title=Get support and troubleshooting assistance
support.description=Get support through email, Twitter, Whatsapp or over the phone
support.tagline= Any issue or suggestion? Get in touch!
support.phonecall.title=Phone call
support.phonecall.details=Offering support over the phone is an experiment, <a href="https://news.ycombinator.com/item?id=28594313" target="_blank">based on this story</a>. Let's see where it leads.

acknowledgements.title= Acknowledgements - thanks to those making Nocode functions possible
acknowledgements.description= Thanking individuals and organizations for the tools they build and that support Nocode functions
acknowledgements.tagline= Thank you!
acknowledgements.argument1.title= Thanks to the dev community for providing tools and support and for sharing their knowledge. This app leverages these projects:


# UMIGON
umigon.general.sentiment= sentiment
umigon.general.negativesentiment= negative sentiment
umigon.general.positivesentiment= positive sentiment
umigon.general.neutralsentiment= neutral sentiment
umigon.sentiment_analysis_tool.description=100% free online sentiment analysis tool for non coders, no registration required. Import your text from Twitter in csv, Excel and Google spreadsheets. Performance is as good as or better than Python tools. Run the analysis in one click. Download your results in Excel.
umigon.sentiment_analysis_tool.argument1.title=Analysis of sentiments for Twitter, Instagram and beyond
umigon.sentiment_analysis_tool.argument1.details=\
    This function performs <strong><a href="https://en.wikipedia.org/wiki/Sentiment_analysis" target="_blank">sentiment analysis</a></strong>, also called opinion mining. It analyzes the text and determines whether the sentiment is neutral, positive or negative.\
    <br/>\
    It works best on <strong>social media</strong> such as tweets for Twitter, comments on Instagram posts and other very short texts in English or French. \
    In a comparison with 23 alternatives, this tool was found to be the best <a href="https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-016-0085-1" target="blank">tool for sentiment analysis on social media</a>.\
    <br/>\
    Born in 2012, this tool is under continuous development.\
    <br/>\
    <br/>\
    If you use this function in an academic context (research or studies), you must reference it in your bibliography:\
    <br/>\
    <br/>\
    Levallois, Clement. "Umigon: Sentiment analysis on Tweets based on terms lists and heuristics". Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval), 2013, Atlanta, Georgia.\


umigon.sentiment_analysis_tool.argument3.title=Fast and performant
umigon.sentiment_analysis_tool.argument3.details=\
    The function is programmed in Java. His code is accessible <a href="https://github.com/stars/seinecle/lists/sentiment-emotion-analysis" target="_blank">freely on Github</a>. \
     Its performance is excellent because it does not rely on <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging" target="_blank">part-of-speech taggging (POS tagging)</ a>, which makes it fast. \
     <a href="https://en.wikipedia.org/wiki/Concurrent_computing" target="_blank">Concurrent computing</a> techniques are used in sub-functions and great attention has been paid to overall performance. 

umigon.sentiment_analysis_tool.model_short_description.details=\
The function examines each term of the text and applies a series of rules to determine the effect on the sentiment. \
It also systematically considers <strong>emojis</strong>, punctuation, <strong>hashtags</strong>, variations in spelling, capitalized words... to determine the sentiment.

umigon.sentiment_analysis_tool.model_long_description.details=\
    <p>\
         The principles followed by the tool are described in this academic publication about <a href="https://aclanthology.org/S13-2068/" target="_blank">Umigon, published in the anthology of the Association fo Computational Linguistics</a>. \
        The tool follows these steps:\
     </p>\
     <ol>\
         <li>check on the length of the text: if it is just a couple of words short, it will not be classified</li>\
         <li>removal of urls, removal of content in quotes, normalization of apostrophs</li>\
         <li>two versions of the text are established: one where all the accents and special characters are removed, and one where they are retained. All the following steps will apply to both versions of the text.</li>\
         <li>check on <strong>emojis, emoticons and onomatopeia</strong>. Do not preprocess your text to remove them, they provide useful information on sentiment!</li>\
         <li>check on hashtags, if any</li>\
         <li>decomposition of the text in n-grams up to four-grams</li>\
         <li> for each n-gram:\
             <ul>\
                 <li>skip it if it belongs to a pre-established list of stop words</li>\
                 <li>check for repeated characters and remove them as necessary (<code>yeeeahhh!</code> becomes <code>yeah!</code>)</li>\
                 <li>check if the n-gram is contained in the pre-established list of potentially positive words. If so, the corresponding rule is applied. Most often the rule is as simple as "a positive word gives a positive sentiment to the text", but more complex rules are also included of course.</li>\
                 <li>check if the n-gram is contained in the pre-established list of potentially negative words. Same logic applies</li>\
             </ul>\
         </li>\
         <li>final checks: detection of moderators in the sentence ("but", "however", "even if", etc.). Positive or negative values placed before or after these moderators are kept or get deleted.</li>\
         <li>final decision following complex rules, based on the results of the previous steps.</li>\
     </ol>\

umigon.sentiment_analysis_tool.argument6.title=Scoring, percentage and emotions?
umigon.sentiment_analysis_tool.argument6.details=\
    <p>\
    Some tools provide a scoring to express the strength of the sentiment: a large value for a very positive sentiment, and a very low value for a negative sentiment. \
    Zero represents a neutral sentiment. \
    In my experience, these scorings are not super reliable, except for the obvious cases. \
    "Horrible" will score really low, and "wonderful" will score really high. \
    But in the middle, things are less straightforward and the scorings are much harder to interpret - I would not advise to rely on them. \
    A more promising road would be to introduce <strong>emotions</strong> to tease out the finer nunances of sentiment, beyond the positive / neutral / negative categories. \
    Drop an email at admin@clementlevallois.net if you are interested in this direction of research.\
    </p>\

umigon.sentiment_analysis_tool.argument7.title=Positive, neutral and negative sentiments: further considerations
umigon.sentiment_analysis_tool.argument7.details=\
    <p>\
        This tool identifies subjective markers of <u>sentiment</u>, NOT positive or negative <u>factual statements</u>. To give an example:\
    </p>\
    <br/>\
    <ul>\
        <li>\
            "<code>This country is at war</code>" -> it is classified as <strong>NEUTRAL</strong>, even if a country at war is "objectively" or "factually" not a positive thing.\
        </li>\
        <li>\
            "<code>War is horrible :(</code>" -> it is classified as <strong>NEGATIVE</strong> because the term "horrible" and the emoji are subjective markers of a negative sentiment.\
        </li>\
        <li>\
            "<code>War of the sexes is an exciting research topic!</code>" -> it is classified as <strong>POSITIVE</strong> because the term "exciting" is a subjective marker of a positive sentiment.\
        </li>\
    </ul>\
    <br/>\
    We believe this approach makes sentiment analysis reliable and really unique in the landscape of tools for opinion mining and sentiment analysis. Ready to try it?\

#TOPICS
topics.topics_extraction_tool.title=\ud83d\udd26 Topic extraction tool, free and online. Click and point and no code.
topics.topics_extraction_tool.description=100% free online topic extraction tool \ud83d\udd26 for non coders, no registration required. Import your text from Twitter in csv, Excel and Google spreadsheets. Performance is as good as or better than Python tools. Run the analysis in one click. Download your results in Excel.
topics.topics_extraction_tool.tagline=\ud83d\udd26 Free topic extraction tool for documents and social media
topics.topics_extraction_tool.argument1.title=Topic extraction - automate the analysis of key topics in your texts
topics.topics_extraction_tool.argument1.details=\
    This function identifies automatically the key topics in a text, an operation called <strong>topic extraction</strong> or <strong><a href="https://en.wikipedia.org/wiki/Topic_model" target="_blank">topic modelling</a></strong>. It analyzes the text line by line and determines groups of words and expressions which tend to <strong>cluster</strong> together, forming topics.\
    <br/>\
    It works on texts written in a large variety of languages (including texts in non Latin alphabet). The function follows the principles of unsupervised learning, which is a type of <strong>machine learning</strong>.\
    <br/>\
    <br/>\
    If you use this function in an academic context (research or studies), you must reference it in your bibliography:\
    <br/>\
    <br/>\
    Benabdelkrim, M., Levallois, C., Savinien, J., &amp; Robardet, C. (2020). Opening Fields: A Methodological Contribution to the Identification of Heterogeneous Actors in Unbounded Relational Orders. M@n@gement, 23(1), 4-18.

topics.topics_extraction_tool.argument2.title=Innovative: control how "big" or "micro" the topics will be
topics.topics_extraction_tool.argument2.details=\
    The technology includes a "precision" parameter to control finely if you need big ("macro") topics to be found, or instead if you prefer to identify many "micro" (smaller) topics.

topics.topics_extraction_tool.model_short_description.details=\
    The function identifies pairs of terms in each line of the text. These pairs are called cooccurrences. Aggregating all pairs of terms, a network of terms is constructed. The network is cut into subregions, and each subregion corresponds to a topic.

topics.topics_extraction_tool.model_long_description.details=\
                <p>\
                    The principles followed by the tool are described in this academic publication studying <a href="https://management-aims.com/index.php/mgmt/article/view/4245" target="_blank">how to find communities and topics on Twitter</a>. The technology follows these steps:\
                </p>\
                <ol>\
                    <li>cleaning of the text: flatten to ASCII, removal of urls, removal of punctuation signs.</li>\
                    <li>lemmatization.</li>\
                    <li>decomposition of the text in n-grams up to four-grams, removal of less relevant n-grams. This step is identical to the one followed by the <a href="../umigon/sentiment_analysis_tool.html">function for sentiment analysis</a></li>\
                    <li>count of cooccurrences: which pairs of n-grams tend to appear frequently in the same lines of the text?</li>\
                    <li>the list of cooccurring n-grams is used to create a network: it is made of the most frequent n-grams. Two n-grams are connected if they are frequently cooccurring.</li>\
                    <li>a community detection algorithm is applied to the network: the Louvain algorithm, which is fast and very effective.</li>\
                    <li>the parameter chosen by the user is applied: a large value will detect a few big communities. A small value will detect many little communities.</li>\
                    <li>each community (or cluster) in the network is a topic. The list of key terms in the topic are the n-grams contained in the cluster.</li>\
                </ol>\

topics.topics_extraction_tool.argument3.title=Tips and tricks for effective results in topic detection
topics.topics_extraction_tool.argument3.details=\
    <p>\
        <strong>Structure and format of the text</strong>: Topic extraction works by detecting pairs of terms which appear on the same line of text. So you should be careful about how your text is formatted. Ideally, it should be made of relatively short paragraphs, each on one line. If you are using an Excel file, each paragraph or significant block of text should appear on a different row.\
        <br/>\
        <br/>\
        <strong>Volume of text</strong>: topics are found by measuring frequencies: which pair of terms tend to co-occur most often? For this to work, the text should be sufficiently long so that these counts are meaningful. The longer the text, the better. Texts of at least 5,000 words seem a good start.\
    </p>\

topics.topics_extraction_tool.argument4.title=How to define the number of topics to be found? Is it a good thing?
topics.topics_extraction_tool.argument4.details=\
                <p>\
                    The most classic approach for topic detection is based on a clustering technique called the <a href="https://en.wikipedia.org/wiki/K-means_clustering" target="_blank">"k-means"</a>. With it, the user decides how many topic should be found in the text, and then the algorithms finds these topics.\
                    <br/>\
                    This approach can make sense when we know in advance how many topics there are in the text. But what is the point of topic detection if we know the topics already? \ud83e\udd14\
                    <br/>\
                    In nocode functions, the number of topics to be found is not predetermined. The analyst wil learn a lot by discovering how many topics the algorithm can find in the text, without a preset limit. The analyst remains fully in control thanks to the precision parameter, which helps tune the algorithm to find more or less topics - but always with a degree of freedom on the exact number.\
                </p>\

topics.topics.parameter_precision.explanation=\
    50 is the default. \
    Choose a lower value to find <strong>more and smaller</strong> topics, and choose a larger value to find <strong>less and bigger</strong> topics:\
    <br/>\
    <br/>\
    <small>smaller values => find many 'smaller' topics.</small>\
    <br/>

topics.topics.parameter_stopwords.explanation=\
    Remove 'scientific' stopwords: words which are typical of the academic discourse and that do not carry specific information value (texts in English or French only). The full list is available <a href="https://github.com/seinecle/Stopwords/tree/master/src/main/java/net/clementlevallois/stopwords/resources" target="_blank">here</a>.

topics.results.title=Identify topics in your texts - results
organic.title=\ud83d\udce2 Organic listening of the voice of customer: free and online tool.
organic.description=100% free online tool to identify organic content on Twitter, Instagram and social media. Detect promoted \ud83d\udce2 vs spontaneous \ud83c\udf3f comments on social media.
organic.tagline=Analysis of organic voice of customer for Twitter, Instagram and beyond
organic.details=\
    This function classifies your texts in two categories:\
    <ul>\
        <li><strong>organic</strong>: when the text is written in a style which is natural, personal, individual.</li>\
        <li><strong>promoted</strong>: when the text is written in a style which is corporate, sponsored, artificial.</li>\
    </ul>\
    It works best on <strong>social media</strong> such as tweets for Twitter, comments on Instagram posts and other very short texts in English and French.\
    <br/>\
    Born in 2020, this tool is under continuous development.

organic.general.argument1.title=\ud83d\ude80 Fast and performant
organic.general.argument1.details=The tool is programmed with Java which performances are similar too, or better than <strong>Python</strong>. It does not rely on <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging" target="blank">part-of-speech tagging (POS tagging)</a>, which makes it even faster. Parallel computing is used in subfunctions and great care has been given to performance.
organic.general.model_short_description=\
    The function examines each term of the text and applies a series of rules (in this context, is the term organic or promoted?). It also considers <strong>emojis</strong>, punctuation, <strong>hashtags</strong>, capitalized words... to determine the result.
organic.general.model_long_description=\
    <p>The principles followed by the tool are similar to <a href="../umigon/sentiment_analysis_tool.html">the function for sentiment analysis</a>, except for the rules to be applied. The tool follows these steps:</p>\n<ol>\n<li>check on the length of the text: if it is just a couple of words short, it will not be classified</li>\n<li>removal of urls, removal of content in quotes, normalization of apostrophs</li>\n<li>two versions of the text are established: one where all the accents and special characters are removed, and one where they are retained. All the following steps will apply to both versions of the text.</li>\n<li>check on <strong>emojis, emoticons and onomatopeia</strong>. Do not preprocess your text to remove them, they provide useful information on sentiment!</li>\n<li>check on hashtags, if any</li>\n<li>decomposition of the text in n-grams up to four-grams</li>\n<li> for each n-gram:\n<ul>\n<li>skip it if it belongs to a pre-established list of stop words</li>\n<li>check for repeated characters and remove them as necessary (<code>yeeeahhh!</code> becomes <code>yeah!</code>)</li>\n<li>check if the n-gram is contained in the pre-established list of vocabulary / expressions / style signalling "corporate speech". If so, the corresponding rule is applied.</li>\n</ul>\n</li>\n<li>final decision, based on the results of the previous steps.</li>\n</ol>

organic.general.argument2.title=Organic vs promoted content: further considerations
organic.general.argument2.details=\
    <p>\
        This tool identifies markers of <u>corporate speak</u>. This characterization is not clearly defined in the academic literature. The intent is to provide content managers and analysts a tool which allows them to filter out content which does not represent a <strong>genuine voice of the customer</strong>, such as:\
    </p>\
    <br/>\
    <ul>\
        <li>\
            <strong>calls to action</strong>: "VOTE", "BUY", "PLAY", ...\
        </li>\
        <li>\
            <strong>promotional invitations</strong>: "hottest deals", "give away", ...    \
        </li>\
        <li>\
            <strong>expressions of opinion which are crafted by a communication specialist</strong>, as hinted by the specific terms used: "unveiled", "stoked to", "reinvents" ...  \
        </li>\
    </ul>\
    <br/>\
    This is work in progress and we welcome your feedback and suggestions (analysis@exploreyourdata.com). We believe this function is already extremely useful, helping analysts specializing in opinion mining clean their dataset from the content which does not originate from individuals / customers but from corporations and communication officers (check our <a href="../umigon/sentiment_analysis_tool.html">function for sentiment analysis</a>). This will make their measurement more reliable, especially for opinion mining.


organic.general.soundsorganic= natural / genuine voice
organic.general.soundspromoted= corporate / sponsored voice
organic.general.tone_of_voice=tone of voice
network_converter.title=Online tool to convert gexf files to vosviewer json format, and back
network_converter.choose_file_or_read_below=Choose a file to convert or read below about Gephi and VOSviewer.
network_converter.option1=Option 1: convert a Gephi gexf file to a VOSviewer json file [and optionally, share the file immediately as a web visualization]
network_converter.option2=Option 2: convert a VOSviewer json file to a Gephi file (.gexf format)
general.message.file_loaded=\ud83d\ude9a file loaded!
network_converter.click_to_convert=Now, click the button below to convert it.
network_converter.warning_not_gephi_file=\u26a1 The file should be a <strong>.gexf file</strong>, not a <strong>.gephi file</strong>!\n<a href="https://seinecle.github.io/gephi-tutorials/generated-html/simple-project-from-a-to-z-en.html#_export_a_network_as_a_web_visualization" target="_blank">See all the details here</a>\n<br/>\n\ud83d\udea8 The network should be made of 500 nodes or less - otherwise the online visualization will be impossible to read. See below for details.\n<br/>\n<br/>
general.message.max_file_size=\ud83d\udcda Maximum file size
network_converter.convert_to_vosviewer=Convert to VOSviewer json file
network_converter.share_vosviewer_publicly.question=Make the VOSviewer visualization shareable on the web with a public url?
network_converter.share_vosviewer_publicly.details=<p>When you make the visualization public, a permanent link is generated. You can bookmark it and share the visualization.</p>\n<p>More information in this <a href="https://seinecle.github.io/gephi-tutorials/generated-html/simple-project-from-a-to-z-en.html#_3_public_or_private_web_visualization_how_to_manage" target="_blank">Gephi tutorial</a>.</p>\n
network_converter.convert_to_gephi=Convert to Gephi (create a gexf file)
network_converter.howto=Not sure about how to get a gexf file from Gephi? Visit this <a href="https://seinecle.github.io/gephi-tutorials/generated-html/simple-project-from-a-to-z-en.html#_export_a_network_as_a_web_visualization" target="_blank">detailed tutorial on how to go from Gephi to a web visualization with VOSviewer</a>.
network_converter.limit_to_500_nodes.question=What about the limit to 500 nodes?
network_converter.limit_to_500_nodes.details=<p>\n  While Gephi is made for small and very large networks, VOSviewer is made for networks up to about 500 nodes. 300 nodes is even preferable. Above this size, the visualization becomes harder to read and the operations become very slow.\n  </p>\n  <br/>\n  <p>\n  What if your network is bigger than 500 nodes? Nocodefunctions helps you: in the gexf file, it will select the 500 nodes <strong>in the edges that have the larger weight</strong>. The other nodes will be filtered out. This should produce a smaller network which still gives a helpful view of the original, complete network.\n</p>
network_converter.customize_legend.title=Optional: add legends to the elements of your network.
general.nouns.item=item
network_converter.items.question=What do the "items" (or nodes, or agents...) in your network represent? Give it a short name
general.nouns.link=link (edge)
network_converter.links.question=What do the "links" (or edges, or bonds...) in your network represent? Choose a short name
general.nouns.link_strength=strength ('weight') of the link
network_converter.links_strength.question=What do the "link strength" (or weight) in your network represent? Choose a short description.
general.message.gephi.long_title=Gephi - a generalist free software for network visualization
general.message.gephi.description=<p>\n<a href="https://gephi.org/" target="_blank">Gephi</a> is a free desktop software to create, visualize and explore small and large networks.\nThe user can import, layout, filter, colorize, resize, and compute key metrics on the network.\n</p>\n<p>                            \nThis makes it an effective tool for the visual exploration of network data and for the visual communication of such data.                            \n</p>\n<p>\nUseful links: <a href="https://seinecle.github.io/gephi-tutorials/" target="_blank">Tutorials for Gephi</a> and the very active <a href="https://www.facebook.com/groups/gephi" target="_blank">Facebook group of Gephi users</a>.\n</p>
general.message.vosviewer.long_title=VOSviewer - from scientometrics to generalist app to visualize semantic networks
general.message.vosviewer.description=<p>\n<a href="https://www.vosviewer.com/" target="_blank">VOSviewer</a> is a free desktop software to create and visualize networks, with advanced capabilities in the domain of <a href="https://en.wikipedia.org/wiki/Scientometrics" target="_blank">scientometrics</a> (which, briefly said, consists in the measurement and assessment of the scientific activity).\n</p>\n<p>\nIn Summer 2021, the developers of VOSviewer have launched <a href="https://github.com/neesjanvaneck/VOSviewer-Online/" target="_blank">an online version</a>, which makes it very practical to share the visualizations created on it.\n</p>\n<p>\nUseful links: <a href="https://www.vosviewer.com/getting-started" target="_blank">Getting started with VOSviewer</a> which offers a collection of resources.\n</p>
network_converter.creating_a_bridge.title=Creating a bridge between Gephi and VOSviewer
network_converter.creating_a_bridge.details_first_part=<p>\nNetwork data can be formatted according to different conventions: GraphML, DL, or Pajek Net are among the most common ones.\nThis <a href="https://gephi.org/users/supported-graph-formats/" target="_blank">table of network file formats</a> makes a useful (if incomplete) recap:\n</p>
network_converter.creating_a_bridge.details_second_part=<p>\nWhat makes things impractical is that not all network viz software accept all formats. In particular:\n<ul>\n<li>Gephi can import and export gexf files, but it does not recognize VOSviewer json network files</li>\n<li>VOSviewer can import and export VOSviewer json files, but it does not recognize gexf files</li>\n</ul>                            \n</p>\n<p>\nThe converter between gexf and VOSviewer json files offered on this page is a bridge which I hope will be found useful by the users of both software.\n</p>
link_prediction.title=\ud83d\udd2e\ufe0f\ufe0f\ufe0f Online tool to predict new links in a network
link_prediction.description=Free online tool using preferential attachement to predict new links in a network
link_prediction.tagline=\ud83d\udd2e\ufe0f\ufe0f\ufe0f Predict new links in a network
link_prediction.choose_gexf_or_read_below=Choose a gexf file where new links will be predicted or read below about the methodology
link_prediction.how_many_links=How many links do you want to predict?
link_prediction.warning_size=\ud83d\udea8 The network should be made of 1000 nodes or less - otherwise the computations are goint to be very slow. See below for details.
link_prediction.predict_new_links=Predict new links
link_prediction.success=\ud83d\ude9a the predictions are in! You can see the list of predicted links below. A gexf file has been downloaded, it includes the predicted links on top of the original network.
link_prediction.list_predicted_links=List of predicted links
general.nouns.label=label
general.nouns.node_target=node (target)
general.nouns.node_source=node (source)
link_prediction.node_prediction_value=node prediction value
link_prediction.how_to_interpret.question=How to interpret this prediction value?
general.small_words.and=and
general.message.are_not_connected=are not connected
general.small_words.has=has
general.nouns.connections=connections
general.message.the_product_of=The product of
general.small_words.is=is
link_prediction.short_explanation=<p>\nThe method predicts that the nodes that have the highest <strong>product</strong> have the highest chance to get connected.\nThis assumption is called <strong><a href="https://en.wikipedia.org/wiki/Preferential_attachment" target="_blank">preferential attachment</a></strong>: the nodes that already have the most connections, tend to be the ones that create new relations.\n</p> 
link_prediction.explanation.title=Preferential attachement  - a method to predict new "probable" links in a network
link_prediction.explanation.details=<p>\nThis function is a direct application of the Gephi plugin by <a href="https://web.fhnw.ch/technik/projekte/i/ip519/I4DS01/index.html" target="_blank">Marco Romanutti and Saskia Sch\u00fcler, supervised by Michael Henninger at FHNW</a>.\n</p>\n<br/>\n<p>\nTheir code is visible <a href="https://github.com/romanutti/gephi-plugins/tree/master/modules/LinkPrediction" target="_blank">on Github</a>.\n</p>\n<br/>\n<p>\nThe prediction is based on <a href="https://en.wikipedia.org/wiki/Preferential_attachment" target="_blank">preferential attachement</a>.\n It is limited to undirected, unweighted networks. The reasoning is simple: the most likely link to be created is the one between two nodes which have the most neighbors, but don't have a connection yet.\n</p>\n<br/>\n<p>\nHow to interpret this link prediction? The absence of a link can mean that:\n<br/>\n<ol>\n<li>\nThere is no potential for this link (it is not "relevant" to the nodes that would be involved)\n</li>\n<li>\nThere is a potential for this link to get created, and this potential is not actualized yet\n</li>\n<li>\nThere is a potential for the link but the two nodes choose not to actualize the link\n</li>\n</ol>\n<br/>\nThis means that "predicting" a link can address one of these three cases.\n<br/>\n<br/>\nResearch on link prediction is fascinating. Contact us if you want to implement a new link prediction method on nocodefunctions.com!\n</p> 
labelling_task_management.title=Annotation tasks - task management
labelling_task_management.description=Manage the annotation tasks you ceeated (edit, delete)
=
labelling_task_management.tagline=\ud83d\udccf\ufe0f Data annotation tasks: task management page
labelling_task_management.manage_annotators.title=Manage the annotators for this task
labelling_task_management.manage_annotators.button=Go manage annotators
labelling_task_management.show_bws_scores.title=Visualize the "Best-Worst Scaling" scores for each item
general.message.open_the_chart=Open the chart
labelling_task_management.public_link_title=Public url which you can share with any annotator
general.message.back_to_the_menu=Back to the menu
labelling_task_definition_categorization.title=Categorization - defining the parameters of the task
labelling_task_definition_categorization.description=A page to set all the parameters of a categorization annotation task
labelling_task_definition_categorization.tagline=\ud83c\udf9b\ufe0f Parameters for the task consisting of categorizing items
general.nouns.categories=categories
labelling_task_definition_categorization.which_categories_question=Annotators will categorize the items. What are the categories they should choose from?
general.verbs.confirm=confirm
general.verbs.remove=remove
labelling_task_definition_categorization.add_new_category=Add a new category
general.verbs.save=save
general.nouns.additional_parameters=additional parameters
labelling_task_general.check_box_when_free_comment_allowed=Check this box if annotators <u>can add a free comment</u> to their annotations.
labelling_task_general.check_box_when_multiple_categories_allowed=Check this box if annotators can decide that one item can belong to <u>multiple</u> categories.
labelling_task_general.public_url=Check this box to make your task 'public': it will generate a url (a web link), so that <u>anyone with the link</u> will be able to perform annotations (that can be very convenient!)
general.message.confirm_and_back_to_menu=Confirm your parameters and get back to the main panel
labelling_task_definition_bws.title="Best-Worst Scaling" - defining the parameters of the task
labelling_task_definition_bws.description=A page to set all the parameters of a "Best-Worst Scaling" annotation task
labelling_task_definition_bws.tagline=\ud83c\udf9b\ufe0f Parameters for the "Best-Worst Scaling" task you are creating
labelling_task_definition_bws.fixed_param.title=Fixed parameter: number of items \u00e0 annoter
general.message.dataset_is_made_of=The dataset you uploaded is made of
general.nouns.items=items
labelling_task_general.instructions_for_annotators.title=Instructions for the annotators
labelling_task_definition_bws.instructions.part1=<p>The annotators will be asked to pick the best and worst options among a number of items presented simultaneously.</p>\n<p>We use a drag and drop effect: the annotator will choose the best option <strong>by using the mouse and moving it to the top</strong>, and moving the worst option to the bottom, like so:</p>\n
labelling_task_definition_bws.instructions.part2=<p>\n<strong>\nThis instruction will be displayed to the annotators:\n</strong>\n</p>\n<br/>\n<p>\n"The person who invited you to be an annotator for this task must have communicated wha notion you are evaluating here. <strong>Your role is to choose 2 items in the list:</strong> the item that fits best this notion, and the item that fits this notion the least.\n</p>\n<br/>\n<p>\n"To choose the best item, <strong>slide up the best item</strong> with the mouse (or touch the screen on mobile) to the top of the list. <strong>Slide down</strong> the worst item to the bottom of the list.\n</p>
labelling_task_definition_bws.block_size.title=Number of items per block (size of a block)
labelling_task_definition_bws.block_size.details=Annotators will compare items gathered in small groups.  How many items should there be in a group? (in a 'block')?\n<br/>\n<br/>\n<strong>\nThe defaut, standard size of a block is 4: an annotator will compare 4 items at a time.\n</strong>
labelling_task_definition_bws.nb_times.title=Number of times an item should be annotated
labelling_task_definition_bws.nb_times.details=Each item needs to be annotated at least once, obviously. To increase the accuracy of the annotation, it is preferable to have the item presented several times (in different blocks), possibly to different annotators.\n<br/>\n<br/>\nThe defaut value of 4 times yields a very good accuracy. Increasing this value will automatically lead to many more comparisons to be done by the annotators (see the count just below).
labelling_task_definition_bws.results_total.title=Result: the total number of blocks to be annotated
labelling_task_definition_bws.results_total.details=<p>\nThe number of blocks to annotate (or 'groups of items to compare') depends directly from the 3 parameters you have set above:\n</p>\n<ul>\n<li>the number of items to be annotated (fixed, depends on the number of elements in the file you have uploaded</li>\n<li>the number of items to compare together, or 'size of a block'</li>\n<li>the number of times an item should be annotated</li>\n</ul>\n<br/>\n<strong>\nPut together, these parameters lead to this total number of annotation tasks (or 'blocks'): "\n</strong>
labelling_task_definition_bws.nb_annotators.title=Choose the number of annotators
labelling_task_definition_bws.nb_annotators.details=<p>Once you leave this page, the number of annotators for this list of items cannot be changed. <strong>Please choose carefully</strong>.\n</p>\n<br/>\n<br/>\nNumber of annotators:
labelling_task_definition_bws.or_make_public=Or, check this box to make your task 'public': it will generate an url, <strong>anyone with the link will be able to perform annotations</strong>.
labelling_task_definition_bws.or_make_public.button=Make this task 'public'
labelling_task_definition_bws.nb_task_per_annotator=Number of tasks (aka, blocks to annotate) per annotator
labelling_task_definition_bws.actual_number_tasks_might_differ=The actual number of tasks per annotator might slightly differ - to make sure that all items are effectively annotated the required number of times. The actual number will appear below.
labelling_task_definition_bws.if_too_many_tasks=(if this value is too high - too much work per annotator! - change the parameters above. Or upload a smaller list of items...)
labelling_task_definition_bws.confirm_params_and_generate_blocks=Confirm your parameters and generate the blocks
labelling_task_definition_bws.blocks_generated_click_for_next_steps=The blocks have been generated. Click for the next steps
labelling_task_definition_bws.nb_series=Number of series of blocks (one series per annotator)
general.nouns.annotator=Annotator
labelling_task_definition_bws.nb_blocks=Number of blocks to annotate
labelling_task_definition_bws.complete_list_reference=Complete list of parameters for the task, for reference.
labelling_task_definition_bws.canonical_bibd=1. Canonical BIBD parameters <a href="https://en.wikipedia.org/wiki/Block_design" target="_blank">BIBD ("Balanced Incomplete Block Design")</a>\n                      
labelling_task_definition_bws.nb_items=Number of items
labelling_task_definition_bws.nb_blocks_given_item=Number of blocks containing a given item
labelling_task_definition_bws.nb_blocks_2_distinct_items=Number of blocs containing any 2 distinct items
labelling_task_definition_bws.in_practice=<p>2. In practice, a perfect BIBD is not always possible for all combinations of the parameters v, r, k and lambda \u03bb. As v (number of items) is fixed, k, r and lambda \u03bb will probably differ from their theorerical values.</p>\n<p>Below are the actual parameters of the task just created:</p>\n
labelling_task_definition_bws.actuallambda=This actual value for <strong>lambda \u03bb</strong> means that on average, two items appear in the same blocks this number of times:
labelling_task_definition.nb_annotators=Number of annotators:
labelling_task_definition.public_link_generated=This annotation task is public: a url has been generated and anyone with this link will be able to add annotations.
labelling_role.title=Create online data annotation tasks for free: Best Worst Scaling and categorization
labelling_role.description=Free data labelling tasks that run online and on mobile devices. Free and respectful of your data.
labelling_role.tagline=\ud83d\udccf\ufe0f Free tool to create data labelling tasks
general.verbs.logoff=log off
labelling_role.for_annotators=for annotators
labelling_role.start_annotating=start annotating
labelling_role.your_email_annotators=your email [<span style="color:red">you need to have received an invitation: check your emails and spams!</span>]
general.message.your_email=your email
labelling_role.your_password=your password [<span style="color:red">you will find the password in the invitation you received by email!</span>]
general.message.your_password=your password
labelling_role.login_to_display_tasks=Log in to display the list of tasks you can annotate
labelling_role.what_task_annotate_question=What task would you like to annotate?
general.verbs.select_one=select one
labelling_role.go_annotate=Go annotate! \u270d
labelling_role.to_create_modify_task=to create or modify an annotation task
labelling_role.upload_dataset_create_new_task=Upload a new list of items to annotate
general.message.i_new_user=I am a new user
general.message.password_will_be_sent_to_email=This password will be sent to your email address. Check your spam folder!
labelling_role.which_type_task_question=Which type of annotation task for this dataset?
labelling_role.categorizating_items=Categorizing items
labelling_role.curious_bws=[curious about "Best-Worst Scaling" (BWS)? Read <a href="https://nocodefunctions.com/blog/best-worst-scaling-bws-in-progress/" target="_blank">this short blog post explaining how BWS differs from traditional survey / ranking methods</a>]\n
labelling_role.format_list_items=In what type of file and format is your list of items?
general.message.text_in_bulk_one_item_per_line=Items in a plain .txt file - one item per line \ud83d\udcc4
general.message.text_in_tables_one_item_per_line=Items which are in a specific column of a file (csv or Excel file) \ud83d\udcca
general.message.upload_your_data=Upload your data
labelling_role.manage_existing_task=manage an existing task
labelling_role.login_to_list_tasks_created=Log in to display and manage the tasks you created
labelling_role.login_succcessful_pick_a_task=Login successful! Pick a task in the dropdown menu below
labelling_role.what_task_manage_question=What task would you like to manage?
labelling_role.go_manage_task=Go to the management of this task
labelling.report_categorization.title=Report on results for categorization task
labelling.report_categorization.description=Full report on the results of a categorization task
labelling.report_categorization.tagline=Categorization task: full report on results
general.message.back_to_menu=back to menu
labelling.item_eval.categorization.title=Category labelling - item evaluation
labelling.item_eval.categorization.description=The page where the annotation is actually performed, for tasks consisting in categorizing items
labelling.item_eval.categorization.tagline=\ud83d\udccf\ufe0f Perform the annotation: categorize an item
general.message.you_annotated=you annotated
general.small_words.out_of=out of
labelling.general.you_have_received_annotation.instructions=The person that invited you to be an annotator for this task must have communicated what notion you are evaluating here.
labelling.item_eval.categorization.annotate_injunction=Annotate! To which category(ies) does this item belong? Choose one or several categories (or none!)
labelling.general.free_comment_invitation=If you have any free comment to add, write it here:
labelling.general.confirm_next=CONFIRM &amp; move to next item
labelling.general.confirm_previous=CONFIRM &amp; move back to previous item
labelling.general.skip_previous=SKIP &amp; move back to previous item
labelling.general.skip_next=SKIP &amp; move to next item
labelling.item_eval.bws.instructions=<strong>Your role is to choose 2 items in the list:</strong> the item that fits best this notion, and the item that fits this notion the least.\n<br/>\n<p>\nTo choose the best item, <strong>slide up the best item</strong> with the mouse (or touch the screen on mobile) to the top of the list. <strong>Slide down</strong> the worst item to the bottom of the list.\n</p>\n
labelling.item_eval.bws.tagline=\ud83d\udccf\ufe0f Perform the annotation: choose the best and the worst options
labelling.item_eval.bws.title=Annotation for a best-worst scaling task
labelling.item_eval.bws.description=This is where the annotation is actually performed, for a task of best-worst scaling
labelling.chart_bws.title="Best-Worst Scaling" - chart of results
labelling.chart_bws.description=A graphical presentation of the results of the annotations made for a BWS task
labelling.chart_bws.tagline=\ud83d\udccf\ufe0f "Best-Worst Scaling": visualization of the results
labelling.annotators_management.title=Labelling task - management of annotators
labelling.annotators_management.description=Add and delete annotators for each annotation task you designed
labelling.annotators_management.tagline=\u270d\ufe0f Management of annotators
labelling.annotators_management.reminder=Reminder: the annotators to be created or deleted on this page are related to this dataset:
labelling.annotators_management.add_annotator=Add an annotator
labelling.annotators_management.max_annotators_this_task=The task for this dataset has been setup for this maximum number of annotators:
general.small_words.there_are_still=There are still
labelling.annotators_management.annotators_to_create=annotators to create
labelling.annotators_management.name_new=Name of the new annotator
labelling.annotators_management.email_new=Email of the new annotator (needs to be accurate as they will receive a password)
validation.email_not_valid=email is not valid
labelling.annotators_management.delete_annotator=Delete an annotator
labelling.annotators_management.delete_annotator_warning=Warning: deleting an annotator deletes all their annotations for this dataset!
labelling.annotators_management.delete_annotator_select=Select an annotator to delete (just for this dataset)
general.verbs.delete=delete
labelling_role.h2=have your datasets labelled super easily by annotators you invite, on the web and mobile, or even make it a public annotation task.
general.verbs.wait_exclamation=wait!
general.message.switch_to_desktop=Please switch to a browser on a desktop computer.
import_data.general.upload_a_dataset=Upload a dataset
import_data.general.open_a_file=Open a file
import_data.general.choose_csv_or_excel=Choose a csv or Excel file
import_data.general.click_below_to_read_it=Now, click the link below to read it.
import_data.general.read_data=Read the data in the file(s)
import_data.general.select_two_columns_below=Select two columns (below)
general.small_words.and_then_capitalized=AND THEN
import_data.general.my_data_has_headers=My data has headers
general.nouns.term=term
general.nouns.text=text
import_data.two_columns.title=Import structured data with 2 columns
import_data.two_columns.description=This page allows you to select a file, upload it and then select the two columns where the data of interest is located
import_data.structured_data.title=Import a structured dataset - in csv or table format
import_data.structured_data.description=This page is for you to import a structured dataset to be analyzed by the function you selected
import_data.structured_data.confirm_analysis_on_this_column=the analysis will be performed on this column if you click on 'yes'
import_data.structured_data.click_for_this_column=Click here to analyze data in this column
import_data.structured_data.labelling.short_name=Short name for this dataset:
general.message.keep_it_short_exclamation=keep it short and clear!
general.message.name_of_dataset=name of the dataset
general.message.your_description_here=your description here
import_data.structured_data.labelling.description_visible_to_annotators=This description will be visible to the annotators. Make it clear!
general.message.describe_items_short=Describe these items in a short line:
general.small_words.yes=yes
general.small_words.no=no
import_data.option2.title=A page to import a dataset with sources and targets
import_data.option2.description=Some functions reason on an input dataset which comprises 'source' entities and 'target' entities. This page allows for this import
import_data.option2.file_must_have_columns=Your file must include at least 2 columns: the first one is the source. The column(s) on the right are the targets.
import_data.option2.click_to_select_source=Click here to select this column as the source
import_data.option2.confirm_this_column_is_source=this column is the source, and the column(s) on the right are the target(s). Click on 'yes' to launch the analysis.
import_data.option1.title=A page to import a dataset where co-occurrences will be detected line by line
import_data.option1.description=Some functions need to get for input files where each line will be examined, and within each line there is a list of items. This import page reads such files
import_data.option1.for_Excel_files=for Excel files, each item should be in a column:
import_data.option1.for_csv_files=for plain text files and csv files, the items should be comma separated or any other separator will do as long as it is consistent across the file (space, semi-colon, tabs...)
gaze.network_builder.title=Tool to generate networks, free and online. Turn csv and co-occurrences into graphs.
gaze.network_builder.description=100% free online tool to create networks from lists
gaze.network_builder.tagline=\ud83d\udd27\ufe0f\ufe0f Free tool to create networks from co-occurrences or lists
gaze.network_builder.use_it_directly=Use it directly by choosing an option:
gaze.network_builder.option_1=Option 1: cooccurences to network
gaze.network_builder.option_2=Option 2: sources and targets to network
gaze.network_builder.if_you_need_more_parameters=if you need more parameters \ud83e\udd13
general.nouns.pmi=Pointwise Mutual Information (PMI)
gaze.network_builder.apply_pmi_correction=Apply a <a href="https://en.wikipedia.org/wiki/Pointwise_mutual_information" target="_blank">Pointwise Mutual Correction (PMI) correction</a> to the connections of the network.\n
general.message.use_pmi=use PMI
gaze.network_builder.or_read_below=... or read below about these two options, and how they work:
gaze.network_builder.two_options=Two options: co-occurrences or similarities in lists
gaze.network_builder.tips_and_tricks.title=Tips and tricks to get insights from the network
gaze.network_builder.tips_and_tricks.details=<strong>Exploring the graph</strong>\n<br/>We recommend two free software for the exploration of the semantic network produced by the function:\n<ul>\n<li><a href="https://gephi.org" target="_blank">Gephi</a> provides the best features to filter, colorize, resize and run descriptive graph statistics on your network (such as betweenness centrality).\n</li>\n<li> <a href="https://www.vosviewer.com/" target="_blank">VOSviewer</a> provides the visualizations which are the cleanest and easiest to interpret for semantic networks. VOSviewer is developed with scientometrics as first use case but it is useful for any kind of semantic network.\n</li>\n</ul>
gaze.results.tagline=\ud83d\udd27\ufe0f\ufe0f\ufe0f Gaze: build a network from cooccurrences or similarities - results
gaze.results.title=Results - Create networks from cooccurrences or lists of entities
general.message.download_gexf=download gexf file
general.message.visualize_with_gephisto=visualize with Gephisto
general.message.make_viz_public_question=Make the visualization public?
general.message.make_viz_public_details=<p>When you make the visualization public, a permanent link is generated. You can bookmark it and share the visualization.</p>\n<br/>\n<p>Otherwise, the file is deleted after one hour.</p>
general.message.visualize_with_vosviewer=visualize with VOSviewer
gaze.results.long_explanation=<h3>The function has created a network where:</h3>\n<ul>\n<li>\n<strong>If you chose Option 1 (co-occurrences)</strong>: when 2 expressions co-occur on one or many lines, they are connected in the network\n</li>\n<li>\n<strong>If you chose Option 2 (sources and targets)</strong>: when 2 sources have at least one target in common, they are connected in the network.\n</li>\n</ul>\n\n<h3>Visualize the graph with Gephi, VOSviewer or Gephisto</h3>\n<p>You can download the full network (with many more expressions) as a <strong>gexf file</strong> with all the information about the network. \n<strong>Gexf files</strong> can be opened and explored with <a href="https://gephi.org" target="_blank">Gephi</a>, the leading free desktop software for network visualizations.\n</p>\n<br/>\n<p>\nYou can also directly visualize the network with <a href="https://www.vosviewer.com/" target="_blank">VOSviewer</a> online, the software developed by Nees Jan van Eck and Ludo Waltman at the Centre for Science and Technology Studies (CWTS) at Leiden University.\n</p>\n<br/>\n\n<p>\nLast, <a href="https://jacomyma.github.io/gephisto/" target="_blank">Gephisto</a> is a web application that creates a viz in one click, that you can download as a PNG file.\n</p>\n<br/> 
delight.tool.title=Identify the emotion 'delight' in texts, free and online. Opinion mining for non coders.
delight.tool.description=Free tool to identify 'delight' as an emotion in texts from English social media.
delight.tool.tagline=\ud83d\ude0a \ud83d\ude02 \ud83d\udc4d Free tool to identify delight in texts, for social media in English
delight.results.tagline=Detection of 'delight' in English social media texts - results
general.nouns.sentiment=sentiment
general.small_words.all=all
cowo.tool.title=Tool to generate semantic networks, free and online. Turn texts into graphs.
cowo.tool.description=100% free online tool to create semantic networks. No registration required. Import your text in csv, Excel or plain text. Run the analysis in one click. Download your results in Excel or as a graph.
cowo.tool.tagline=\ud83d\udd78\ufe0f Free tool to turn your texts into semantic graphs
cowo.tool.argument1.title=Semantic networks - turn your texts into graphs
cowo.tool.argument2.details=The function takes one parameter (what is the language of the text?) and runs with one click:\n
cowo.tool.model_short_details=The function identifies pairs of terms in each line of the text. These pairs are called co-occurrences. Aggregating all pairs of terms and selecting the most frequent ones, a network of terms is constructed where any two terms are connected if they often appear together in the text.
cowo.tool.model_long_details=<p>\nThe principles followed by the tool are described in this academic publication studying <a href="https://management-aims.com/index.php/mgmt/article/view/4245" target="_blank">how to find communities and topics on Twitter</a>. The technology follows these steps:\n</p>\n<ol>\n<li>cleaning of the text: flatten to ASCII, removal of urls, removal of punctuation signs.</li>\n<li>lemmatization.</li>\n<li>decomposition of the text in <a href="https://en.wikipedia.org/wiki/N-gram" target="_blank">n-grams</a> up to four-grams, removal of less relevant n-grams. This step is identical to the one followed by the <a href="../umigon/sentiment_analysis_tool.html">function for sentiment analysis</a></li>\n<li>count of <a href="https://en.wikipedia.org/wiki/Co-occurrence" target="_blank">co-occurrences</a>: which pairs of n-grams tend to appear frequently in the same lines of the text?</li>\n<li>the list of cooccurring n-grams is used to create a network: it is made of the most frequent n-grams. Two n-grams are connected if they are frequently cooccurring.</li>\n<li>the strength of the connections in the network is corrected using a procedure called <a href="https://nocodefunctions.com/blog/pmi-tf-idf/" target="_blank">Pointwise Mutual Information (PMI)</a>.</li>\n</ol>
cowo.tool.argument3.title=Tips and tricks to get insights from a semantic network
cowo.tool.argument3.details=<p>\n<strong>Structure and format of the text</strong>: the network is created by detecting pairs of terms which appear on the same line of text. So you should be careful about how your text is split. Ideally, it should be made of relatively short paragraphs, each on one line. If you are using an Excel file, each paragraph or significant block of text should appear on a different row.\n<br/>\n<br/>\n<strong>Pre-processing of the text</strong>: there is no need to pre-process or clean your text before using this function.\n<br/>\n<br/>\n<strong>Exploring the graph</strong>: we recommend two free professional grade software for the exploration of the semantic network produced by the function. <a href="https://gephi.org" target="_blank">Gephi</a> provides the best features to filter, colorize, resize and run descriptive graph statistics on your network (such as <a href="https://en.wikipedia.org/wiki/Betweenness_centrality" target="_blank">betweenness centrality</a>). <a href="https://www.vosviewer.com/" target="_blank">VOSviewer</a> provides the visualizations which are the cleanest and easiest to interpret for semantic networks. VOSviewer is developed with scientometrics as first use case but it is useful for any kind of semantic network.\n</p>\n
cowo.tool.argument4.title=When your text is structured, with lists of items
cowo.tool.argument4.details=If your text is a list of co-occurrences or a list of items, you might want to use Gaze, a function dedicated to <a href="../gaze/network_builder_tool.html">building networks from co-occurrences and similarities</a>.\n
cowo.cowo.title=Cowo: a free online tool to create semantic networks from text
cowo.cowo.tagline=\ud83d\udd78\ufe0f turn your texts into networks - parameters
cowo.cowo.max_size_for_ngrams=Choose the maximum length for ngrams. The default length is:
general.message.max_ngram=Length of ngrams
general.message.min_word_length=minimum word length
cowo.cowo.remove_smaller_words=Remove small words. Default minimum characters for a word is
cowo.cowo.remove_academic_stopwords=Remove 'academic' stopwords: words which are typical of the academic discourse (on texts in English and French only)\n
general.message.remove_academic_stopwords=remove academic stopwords
general.message.use_own_stopwords=use your own stopwords
general.message.use_own_stopwords.instructions=Upload a list of stopwords. It must be a .txt file with one word or n-gram per line.\n
general.message.your_stopwords_replace=click here if your list of stopwords should *replace* the default list of stopwords
general.message.ok_sharing_stopwords=click here if you agree these stopwords can be shared and re-used to improve the app for everyone \ud83d\ude4f
general.nouns.status=status
cowo.results.title=Cowo: turn your texts into networks -results.
cowo.results.tagline=\ud83d\udd78\ufe0f turn your texts into networks - results
cowo.results.long_explanation=<h3>The function has created a network where:</h3>\n<ul>\n<li>only the most frequent expressions appear</li>\n<li>if 2 expressions appear often together in the text, they are connected in the network</li>\n</ul>\n<p>The graph visualized above shows the 20 most frequent expressions in the text.</p>\n\n<h3>Visualize the graph with Gephi, VOSviewer or Gephisto</h3>\n<p>You can download the full network (not just the sample shown here) as a <strong>gexf file</strong> with all the information about the network. <strong>Gexf files</strong> can be opened and explored with <a href="https://gephi.org" target="_blank">Gephi</a>, the leading free desktop software for network visualizations.</p>\n<br/>\n<p>You can also directly visualize the network with <a href="https://www.vosviewer.com/" target="_blank">VOSviewer</a> online, the software developed by Nees Jan van Eck and Ludo Waltman at the Centre for Science and Technology Studies (CWTS) at Leiden University.</p>\n<br/>\n<p>Last, <a href="https://jacomyma.github.io/gephisto/" target="_blank">Gephisto</a> is a web application that creates a viz in one click, that you can download as a PNG file.</p>
import_data.bulk.title=Import your data as plain text
import_data.general.choose_txt_or_pdf=Choose .txt or pdf files
import_data.general.choose_pdf=Choose pdf files
general.message.several_files_possible=You can analyze *several* files at once. To analyze all the files in a folder, open the folder and use 'Ctrl', 'shift' or 'Cmd' keys to select all the files you want to include in the analysis.\n
import_data.general.preview_your_data=Preview of the data in the file you uploaded
highlighter.tool.title=Tool to highlight a term in a text with css styling
highlighter.tool.description=100% free online tool to to highlight a term in a text with css styling. No registration required. Import your text in csv or Excel.
highlighter.tool.tagline=\ud83c\udfa8\ufe0f\ufe0f Free tool to highlight a word in a text with CSS
highlighter.tool.input=<p>\n<strong>INPUT</strong>: This function takes a list of words, plus a list of sentences ("context") where these words appear.\n</p> 
highlighter.tool.output=<p><strong>OUTPUT</strong>: A two-column Excel file ressembling the input, except that the terms are now highlighted in context:</p>\n
general.nouns.context=context
highlighter.tool.input1=I have moved to <span style="background-color: black;color:whitesmoke;">Paris</span>
highlighter.tool.input2=The <span style="background-color: black;color:whitesmoke;">Liverpool FC</span> is a professional football club
highlighter.tool.input3=The Vice President of <span style="background-color: black;color:whitesmoke;">Barack Obama</span> was Joe Biden
highlighter.tool.explanation1=<p>The color effects are the result of adding an html tag: &lt;span&gt; and css styling within it.</p>\n<br/>\n<br/>\n<p>The colors used to highlight can be customized: color of the text and background color (see below).</p> 
highlighter.tool.which_color_word=Which color for the word to highlight?
highlighter.tool.which_color_background=Which background color for the word to highlight?
highlighter.results.tagline=\ud83c\udfa8\ufe0f\ufe0f Free tool to highlight a word in a text - download the results
highlighter.results.title=Free tool to highlight a word in a text with CSS - download the results
highlighter.results.download=Get the file with results
back.bwsbean.warning.task_exists_title=A task has already be defined for this dataset.
back.bwsbean.warning.task_exists_details=Please upload the dataset again, then you will be able to design a task for it.
back.categorizationbean.categories_are_saved=categories are saved
general.message.data_not_found=\ud83e\udd14 data not found
general.nouns.success=success
general.verb.is_uploaded=is uploaded
general.message.choose_gexf_file=Choose a gexf file (Gephi)
general.message.choose_vosviewer_file=Choose a json file (VOSviewer)
general.message.starting_analysis=\ud83c\udfc3 starting the analysis
general.message.removing_punctuation_and_cleaning=\ud83d\udec1 removing punctuations and other cleaning ops
general.message.heavy_duty_lemmatization=\ud83c\udfcb heavy duty lemmatization.
general.message.please_wait_seconds=please wait a few seconds.
general.message.finding_key_terms=\ud83c\udfaf finding key terms and expressions... 
general.message.cleaning_key_terms=\ud83d\udec1 cleaning key terms and expressions... 
general.message.remove_stopwords_small_words=\ud83d\udebf\ufe0f removing stopwords and very small words
general.message.opening_user_supplied_stopwords=\ud83e\udd38 opening user supplied list of stopwords
general.message.sending_user_stopwords_to_dev=\u2709 \ufe0fsending the list of stopwords to the developer - will be integrated soon, thank you! \ud83d\ude4f
general.message.opening_academic_stopwords=\ud83d\udebf\ufe0f opening stopwords from the academic discourse and using them
general_message.retaining_freq_terms=\u2697\ufe0f retaining only the most frequent terms
general_message.counting_pairs_terms=\ud83d\udcbb counting pairs of terms - this is computationally intensive and can take a dozen seconds. Please be patient.
general_message.finished_pairs_removing_less_frequent=\ud83d\udebf\ufe0f finished computing pairs. Removing less frequent ones
general.message.last_ops_creating_network=\ud83c\udfc1\ufe0f last operations: creating the network
general.message.analysis_complete=\u2728 analysis is complete
general.nouns.delight=delight
general.nouns.no_delight=no delight
general.nouns.files=files
general.nouns.file=file
general.nouns.page=page
general.nouns.context=context
general.nouns.occurrences=occurrences
general.message.almost_done=\u23f3 almost done
general.message.user_exists=\ud83d\udea8 User already exists
general.message.user_exists.instructions=Please unselect 'new user' and login with 
general.message.wrong_password=wrong password
general.message.scores_by_annotators=scores by annotators
general.nouns.scores=scores
general.message.you_are_not_logged_in=you are not logged in
general.message.wrong_password_or_email=wrong email or password
general.message.you_are_logged_in=you are logged in
back.labelling.select_task=Select an existing task in the dropdown menu
general.nouns.error=error
back.labelling.error_go_back=Error on the email, or the session timed out? Please go back to the home page and restart the process
back.labelling.warning_annotator_exists=This annotator already exists for this task
back.labelling.warning_annotator_exists.instructions=Please add a different annotator (different email)
back.labelling.all_annotators_provisioned=All annotators were already provisioned for this task. Let's investigate.
back.labelling.annotator_created=annotator created
back.labelling.annotator_deleted=annotator deleted
general.message.email_sent_to=\ud83d\udce7 email sent to:
general.message.check_spam=please check the spam folder
general.message.email_sent=\ud83d\udce7 email sent
back.labelling.no_annotator_selected=no annotator selected
back.labelling.select_annotator=Please select an annotator
back.labelling.annotator_not_found=annotator not found
back.topics.detecting_communities=\ud83c\udfc1\ufe0f last steps: finding topics / communities
general.nouns.sentiment_positive=positive sentiment
general.nouns.sentiment_negative=negative sentiment
general.nouns.sentiment_neutral=neutral sentiment
general.message.no_file_upload_again=\ud83d\ude15 no file to read. Upload a file then try again.
general.message.reading_google_spreadsheet=\ud83d\udc53 Reading the Google spreadsheet
general.message.reading_excel_file=\ud83d\udc53 Reading the Excel spreadsheet
general.message.reading_text_file=\ud83d\udc53 Reading the text file
general.message.reading_csv_file=\ud83d\udc53 Reading the csv file
general.message.reading_pdf_file=\ud83d\udc53 Reading the pdf file
general.message.reading_file=Reading the file 
general.message.finished_reading_data=\u2b50 finished reading the data
back.import.searching_tweets=\ud83d\udd26 searching for tweets
back.import.finished_searching_tweets=\u2b50 finished searching, 
back.import.number_tweets_found=\ tweets found
back.import.file_successful_upload.opening=\u2b50 file "
back.import.file_successful_upload.closing=" successfully uploaded
back.import.reading_sheet=\ud83d\udcc3 reading spreadsheet
back.import.two_columns_needed=\ud83d\ude15 two different columns must be selected: one for the terms, the other for the texts
back.import.select_one_column_per_type=\ud83d\ude15 select exactly one column per type
back.import.term_text_different_columns=\ud83d\ude15 terms and texts should be in different columns
back.labelling_description_needed=please enter a description for this dataset
back.import.one_file_uploaded=one file uploaded
back.import.files_uploaded=files uploaded
umigon.results.tagline=Analysis of sentiments for social media: results
network_converter.tagline=Convert files between Gephi and VOSviewer
link_prediction.click_to_predict=Now, click the button below to predict new links.
pdfmatcher.tool.title=\ud83c\udfaf Select a word as input and find it in the pdf files your provide
pdfmatcher.tool.description=This is a free and online tool to match words in your pdf files
pdfmatcher.tool.tagline=\ud83c\udfaf Identify the pdf files that contain a word of interest, with context
pdfmatcher.tool.select_search_word=select the word or phrase to be searched in the pdf files
pdfmatcher.tool.nb_words_for_context=how many words before and after the target should be retrieved for context?
pdfmatcher.results.title=Match terms of interest in pdf files - results
pdfmatcher.results.tagline=Match terms of interest in pdf files - results
pdfmatcher.pdfmatcher.tagline=No special paramater for this function. Click the button to continue.
index.button.pdfmatcher=\ud83c\udfaf Find terms in pdf files
index.button.gaze=\ud83d\udd27 create networks from lists
index.button.labelling=\u270d\ufe0f Tool for data annotation
index.button.highlighter=\ud83c\udfa8 highlight text with css
index.calltochooseafunction=choose a function:
general.verbs.open_report=open the report
general.verbs.download_results=download the results
general.message.reportsent=report is sent
gaze.network_builder.go_with_option=Choose option
highlighter.tool.what_it_does_question=What is the goal of this function?
header.menu.isitpopular=Counter of visits
header.menu.discuss=Discussion
general.message.text_in_bulk_pdf_only=Select pdf files
sidebar.copypaste_incorrect=copy paste here the incorrect phrasing
sidebar.report_bad_translation=report an error in translation?
sidebar.write_better_phrasing=write your suggestion for a better phrasing
sidebar.report_error_in_app=report an error in the app
general.message.write_here=write here
sidebar.suggestion_new_feature=do you have a suggestion for a new feature?
general.verbs.send=send
general.message.feedback_sent=your feedback has been sent
general.nouns.feedback=feedback
index.argument2=#free, #no registration, #open source
import_data.twitter.title=Search and import tweets
import_data.twitter.launch_the_search=launch the search
import_data.general.preview_your_tweets=Preview of the results of the search on Twitter
back.import.twitter_credentials_not\ found=\ud83e\udd9f credentials for Twitter were not found
import_data.twitter.connect=\ud83d\udcde Connect to Twitter
back.import.error_fetching_tweets=\ud83d\ude1e Error: impossible to fetch tweets
general.message.wait_long_operation=\u23f3 This operation may take some time. Please wait.
back.import.twitter.too_many_requests=\u231b Too many requests to the Twitter API. You must wait and try again.
general.message.see_more_details=more details:
general_message.empty_network_no_connection=\ud83d\ude14 the network has no connection
general.message.type_your_query=Type your query
cowo.tool.argument1.details=
general.message.empty_line=empty line
acknowledgements.argument3.title=Thanks to  Ver\u00f3nica Espinoza for her feedbacks on nocodefunctions.com and on the Umigon function in particular.
acknowledgements.argument4.title=Thanks to Martin Zacarias for his feedback on the pdf matcher function.
acknowledgements.argument2.title=Thanks to Gilles Maltais for his contribution to the Quebec vocabulary.
acknowledgements.argument5.title=Thanks to all the anonymous users for their feedbacks on Umigon through the feedback form.
general.small_words.why=why?
general.nouns.explanations=explanations
umigon.sentiment_analysis_tool.api.try_with_parameters=You can modify these parameters in the url:
umigon.sentiment_analysis_tool.api.text.details=the text to analyze
umigon.sentiment_analysis_tool.api.text-lang.details=the language of the text to anlayze. "en" for English, "fr" for French or "es" for Spanish
umigon.sentiment_analysis_tool.api.explanation.details=this parameter has two values: "on" for rich explanations, or "off" if you just need the result without explanations
umigon.sentiment_analysis_tool.api.output-format.details=choose between 3 values: "plain", "html" or "json"
umigon.sentiment_analysis_tool.api.explanation-lang.details=choose the language of the explanations. The parameter is a two-letter code for the language ("zh" for Chinese, for instance)
general.nouns.line_number=line number
general.message.text_provided_as_input=text provided as input
acknowledgements.argument6.title=Thanks to DMDS students Anna Abreu, Hiya Barnejee, L\u00e9o Couder, Terje Espedal and Aparna Ramakrishnan for their contribution to the early steps of the project on emotion detection
acknowledgements.argument7.title=Thanks to Jos\u00e9 Manuel Le\u00f3n Ranero for helping debugging the Excel import
general.verbs.hide=hide
general.message.go_back_do_search_twitter=go back and do another search on Twitter \ud83d\udd0e
general.message.internal_server_error=Internal server error. Please send a report to analysis@exploreyourdata.com
general.message.max_items_capacity_to_analyze=Maximum number of items that will be analyzed:
general.message.please_use_api_for_bigger_capacity=Please use the API if you need a larger capacity
general.message.captcha_paris=Please fill in this captcha: what is the capital of France?
umigon.sentiment_analysis_tool.title=\ud83d\ude0a \ud83d\ude2c Free sentiment analysis tool for social media in English, French and Spanish
umigon.sentiment_analysis_tool.tagline=\ud83d\ude0a \ud83d\ude2c Free sentiment analysis tool for social media in English, French and Spanish
general.nouns.min_targets=Minimum of shared targets to create a connection
gaze.network_builder.connections_should_have_min_targets_in_common=You can decide that to create a connection, 2 sources should have a least a number of targets in common. The default minimum value is one.
general.message.at_least=At least:
